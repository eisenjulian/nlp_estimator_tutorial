{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nlp_estimators.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"O6iPSmuDbXvq","colab_type":"text"},"cell_type":"markdown","source":["Classifying text with TensorFlow Estimators\n","==="]},{"metadata":{"id":"eB6v9qVLT7q4","colab_type":"text"},"cell_type":"markdown","source":["This notebook demonstrates how to tackle a text classification problem using custom TensorFlow estimators, embeddings and the [tf.layers](https://www.tensorflow.org/api_docs/python/tf/layers) module. Along the way we'll learn about word2vec and transfer learning as a technique to bootstrap model performance when labeled data is a scarce resource.\n","\n","## Setup"]},{"metadata":{"id":"HLcya95hbyAk","colab_type":"text"},"cell_type":"markdown","source":["Let's begin importing the libraries we'll need. This notebook runs in Python 3 and TensorFlow v1.4 or more, but it can run in earlier versions of TensorFlow by replacing some of the import statements to the corresponding paths inside the `contrib` module.\n","\n","### The IMDB Dataset\n","\n","The dataset we wil be using is the IMDB [Large Movie Review Dataset](http://ai.stanford.edu/~amaas/data/sentiment/), which consists of $25,000$ highly polar movie reviews for training, and $25,000$ for testing. We will use this dataset to train a binary classifiation model, able to predict whether a review is positive or negative."]},{"metadata":{"id":"hwq4V3xwMbYk","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"12e9efc9-76dd-457a-de65-21b973fa8944","executionInfo":{"status":"ok","timestamp":1523273466121,"user_tz":180,"elapsed":781,"user":{"displayName":"Julian Eisenschlos","photoUrl":"//lh3.googleusercontent.com/-64ZxueD_a5k/AAAAAAAAAAI/AAAAAAAAY_I/SjD0k9jJ8Ug/s50-c-k-no/photo.jpg","userId":"112692138304087361987"}}},"cell_type":"code","source":["import os\n","import string\n","import tempfile\n","import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from tensorflow.python.keras.datasets import imdb\n","from tensorflow.python.keras.preprocessing import sequence\n","from tensorboard import summary as summary_lib\n","\n","tf.logging.set_verbosity(tf.logging.INFO)\n","print(tf.__version__)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["1.6.0\n"],"name":"stdout"}]},{"metadata":{"id":"Octy5JCMPS7I","colab_type":"text"},"cell_type":"markdown","source":["### Loading the data\n","\n","Keras provides a convenient handler for importing the dataset which is also available as a serialized numpy array `.npz` file to download [here]( https://s3.amazonaws.com/text-datasets/imdb.npz). Each review consists of a series of word indexes that go from $4$ (the most frequent word in the dataset, **the**) to $4999$, which corresponds to **orange**. Index $1$ represents the beginning of the sentence and the index $2$ is assigned to all unknown (also known as *out-of-vocabulary* or *OOV*) tokens. These indexes have been obtained by pre-processing the text data in a pipeline that cleans, normalizes and tokenizes each sentence first and then builds a dictionary indexing each of the tokens by frequency. We are not convering these techniques in this post, but you can take a look at [this chapter](http://www.nltk.org/book/ch03.html) of the NLTK book to learn more.\n","\n","It's standard to limit the size of the vocabulary to prevent the dataset from becoming too sparse and high dimensional, causing potential overfitting. After we've loaded the data in memory we pad each of the sentences with $0$ to a fixed size (here: $200$) so that we have two $2$-dimensional $25000\\times200$ arrays for training and testing respectively.\n","\n"]},{"metadata":{"id":"RStSE6MjAR5s","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":118},"outputId":"0f50c910-8cc9-4c7b-9a42-cd06daf89df6","executionInfo":{"status":"ok","timestamp":1523273476760,"user_tz":180,"elapsed":6981,"user":{"displayName":"Julian Eisenschlos","photoUrl":"//lh3.googleusercontent.com/-64ZxueD_a5k/AAAAAAAAAAI/AAAAAAAAY_I/SjD0k9jJ8Ug/s50-c-k-no/photo.jpg","userId":"112692138304087361987"}}},"cell_type":"code","source":["vocab_size = 5000\n","sentence_size = 200\n","embedding_size = 50\n","model_dir = tempfile.mkdtemp()\n","\n","# we assign the first indices in the vocabulary to special tokens that we use\n","#Â for padding, as start token, and for indicating unknown words\n","pad_id = 0\n","start_id = 1\n","oov_id = 2\n","index_offset = 2\n","\n","print(\"Loading data...\")\n","(x_train_variable, y_train), (x_test_variable, y_test) = imdb.load_data(\n","    num_words=vocab_size, start_char=start_id, oov_char=oov_id,\n","    index_from=index_offset)\n","print(len(y_train), \"train sequences\")\n","print(len(y_test), \"test sequences\")\n","\n","print(\"Pad sequences (samples x time)\")\n","x_train = sequence.pad_sequences(x_train_variable, \n","                                 maxlen=sentence_size,\n","                                 truncating='post',\n","                                 padding='post',\n","                                 value=pad_id)\n","x_test = sequence.pad_sequences(x_test_variable, \n","                                maxlen=sentence_size,\n","                                truncating='post',\n","                                padding='post', \n","                                value=pad_id)\n","print(\"x_train shape:\", x_train.shape)\n","print(\"x_test shape:\", x_test.shape)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Loading data...\n","25000 train sequences\n","25000 test sequences\n","Pad sequences (samples x time)\n","x_train shape: (25000, 200)\n","x_test shape: (25000, 200)\n"],"name":"stdout"}]},{"metadata":{"id":"A1BBYudtvq9w","colab_type":"text"},"cell_type":"markdown","source":["We can use the word index map to inspect how the first review looks like."]},{"metadata":{"id":"N08jsWy3vq9x","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":272},"outputId":"dfd55113-1190-4ac0-8a41-8141286e0360","executionInfo":{"status":"ok","timestamp":1523274024651,"user_tz":180,"elapsed":2185,"user":{"displayName":"Julian Eisenschlos","photoUrl":"//lh3.googleusercontent.com/-64ZxueD_a5k/AAAAAAAAAAI/AAAAAAAAY_I/SjD0k9jJ8Ug/s50-c-k-no/photo.jpg","userId":"112692138304087361987"}}},"cell_type":"code","source":["word_index = imdb.get_word_index()\n","word_inverted_index = {v + index_offset: k for k, v in word_index.items()}\n","\n","# The first indexes in the map are reserved to represent things other than tokens\n","word_inverted_index[pad_id] = '<PAD>'\n","word_inverted_index[start_id] = '<START>'\n","word_inverted_index[oov_id] = '<OOV>'\n","\n","for i in range(0, 10):\n","  print(i, word_inverted_index[i])\n","  \n","def index_to_text(indexes):\n","    return ' '.join([word_inverted_index[i] for i in indexes])\n","\n","print(index_to_text(x_train_variable[0]))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n","1646592/1641221 [==============================]1646592/1641221 [==============================] - 1s 1us/step\n","\n","0 <PAD>\n","1 <START>\n","2 <OOV>\n","3 the\n","4 and\n","5 a\n","6 of\n","7 to\n","8 is\n","9 br\n","<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <OOV> is an amazing actor and now the same being director <OOV> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <OOV> and would recommend it to everyone to watch and the fly <OOV> was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <OOV> to the two little <OOV> that played the <OOV> of norman and paul they were just brilliant children are often left out of the <OOV> list i think because the stars that play them all grown up are such a big <OOV> for the whole film but these children are amazing and should be <OOV> for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was <OOV> with us all\n"],"name":"stdout"}]},{"metadata":{"id":"FKhoMPMtTbul","colab_type":"text"},"cell_type":"markdown","source":["## Building Estimators\n","\n","In the next section we will build several models to make predictions for the labels in the dataset. We will first use canned estimators and then create custom ones for the task. We recommend that you check out [this blog post](https://developers.googleblog.com/2017/11/introducing-tensorflow-feature-columns.html) that explains how to use the `tf.feature_column` module to standardize and abstract how raw input data is processed and [the following one](https://developers.googleblog.com/2017/12/creating-custom-estimators-in-tensorflow.html) that covers in depth how to work with Estimators."]},{"metadata":{"id":"EFf3Z9Mbvq91","colab_type":"text"},"cell_type":"markdown","source":["### From arrays to tensors\n","\n","There's one more thing we need to do get our data ready for TensorFlow. We need to convert the data from numpy arrays into Tensors. Fortunately for us the `Dataset` module has us covered. \n","\n","It provides a handy function, `from_tensor_slices` that creates the dataset to which we can then apply multiple transformations to shuffle, batch and repeat samples and plug into our training pipeline. Moreover, with just a few changes we could be loading the data from files on disk and the framework does all the memory management.\n","\n","We define two input functions: one for processing the training data and one for processing the test data. We shuffle the training data and do not predefine the number of epochs we want to train, while we only need one epoch of the test data for evaluation. We also add an additional `\"len\"` key to both that captures the length of the original, unpadded sequence, which we will use later."]},{"metadata":{"id":"VPLRuDRnvq92","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["x_len_train = np.array([min(len(x), sentence_size) for x in x_train_variable])\n","x_len_test = np.array([min(len(x), sentence_size) for x in x_test_variable])\n","\n","def parser(x, length, y):\n","    features = {\"x\": x, \"len\": length}\n","    return features, y\n","\n","def train_input_fn():\n","    dataset = tf.data.Dataset.from_tensor_slices((x_train, x_len_train, y_train))\n","    dataset = dataset.shuffle(buffer_size=len(x_train_variable))\n","    dataset = dataset.batch(100)\n","    dataset = dataset.map(parser)\n","    dataset = dataset.repeat()\n","    iterator = dataset.make_one_shot_iterator()\n","    return iterator.get_next()\n","\n","def eval_input_fn():\n","    dataset = tf.data.Dataset.from_tensor_slices((x_test, x_len_test, y_test))\n","    dataset = dataset.batch(100)\n","    dataset = dataset.map(parser)\n","    iterator = dataset.make_one_shot_iterator()\n","    return iterator.get_next()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MwCuemrKvq94","colab_type":"text"},"cell_type":"markdown","source":["### Baselines\n","\n","It's always a good practice to start any machine learning project trying out a couple of reliable baselines. Simple is always better and it is key to understand exactly how much we are gaining in terms of performance by adding extra complexity. It may very well be the case that a simple solution is good enough for our requirements.\n","\n","With that in mind, let us start by trying out one of the simplest models out there for text classification. That is, a sparse linear model that gives a weight to each token and adds up all of the results, regardless of the order. The fact that we don't care about the order of the words in the sentence is the reason why this method is generally known as a Bag-of-Words (BOW) approach. Let's see how that works out.\n","\n","We start out by defining the feature column that is used as input to our classifier. As we've seen [in this blog post](https://developers.googleblog.com/2017/11/introducing-tensorflow-feature-columns.html), `categorical_column_with_identity` is the right choice for this pre-processed text input. If we were feeding raw text tokens, other `feature_columns` could do a lot of the pre-processing for us. We can now use the pre-made `LinearClassifier`."]},{"metadata":{"id":"neNiEK31Od96","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":71},"outputId":"76fe017b-3c1c-4d0d-8973-e797de00118b","executionInfo":{"status":"ok","timestamp":1523273591870,"user_tz":180,"elapsed":522,"user":{"displayName":"Julian Eisenschlos","photoUrl":"//lh3.googleusercontent.com/-64ZxueD_a5k/AAAAAAAAAAI/AAAAAAAAY_I/SjD0k9jJ8Ug/s50-c-k-no/photo.jpg","userId":"112692138304087361987"}}},"cell_type":"code","source":["column = tf.feature_column.categorical_column_with_identity('x', vocab_size)\n","classifier = tf.estimator.LinearClassifier(feature_columns=[column], model_dir=os.path.join(model_dir, 'bow_sparse'))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using default config.\n","INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpj4vob2jo/bow_sparse', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb4eb340dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stdout"}]},{"metadata":{"id":"loy6y8VOPN1U","colab_type":"text"},"cell_type":"markdown","source":["Finally, we create a simple function that trains the classifier and additionally creates a precision-recall curve. Note that we do not aim to maximize performance in this blog post, so we only train our models for $25,000$ steps."]},{"metadata":{"id":"NMHErNXuBFHr","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["all_classifiers = {}\n","def train_and_evaluate(classifier):\n","    # Save a reference to the classifier to run predictions later\n","    all_classifiers[classifier.model_dir] = classifier\n","    classifier.train(input_fn=train_input_fn, steps=25000)\n","    eval_results = classifier.evaluate(input_fn=eval_input_fn)\n","    predictions = np.array([p['logistic'][0] for p in classifier.predict(input_fn=eval_input_fn)])\n","        \n","    # Reset the graph to be able to reuse name scopes\n","    tf.reset_default_graph() \n","    # Add a PR summary in addition to the summaries that the classifier writes\n","    pr = summary_lib.pr_curve('precision_recall', predictions=predictions, labels=y_test.astype(bool), num_thresholds=21)\n","    with tf.Session() as sess:\n","        writer = tf.summary.FileWriter(os.path.join(classifier.model_dir, 'eval'), sess.graph)\n","        writer.add_summary(sess.run(pr), global_step=0)\n","        writer.close()\n","#     # Un-comment code to download experiment data from Colaboratory\n","#     from google.colab import files\n","#     model_name = os.path.basename(os.path.normpath(classifier.model_dir))\n","#     ! zip -r {model_name + '.zip'} {classifier.model_dir}\n","#     files.download(model_name + '.zip')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"B2O7WOpCpifk","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":8840},"outputId":"9e2e2688-4cb9-4b0b-e427-b1bc85b780de","executionInfo":{"status":"ok","timestamp":1523274992515,"user_tz":180,"elapsed":268303,"user":{"displayName":"Julian Eisenschlos","photoUrl":"//lh3.googleusercontent.com/-64ZxueD_a5k/AAAAAAAAAAI/AAAAAAAAY_I/SjD0k9jJ8Ug/s50-c-k-no/photo.jpg","userId":"112692138304087361987"}}},"cell_type":"code","source":["train_and_evaluate(classifier)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpj4vob2jo/bow_sparse/model.ckpt-25000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 25001 into /tmp/tmpj4vob2jo/bow_sparse/model.ckpt.\n","INFO:tensorflow:loss = 22.445095, step = 25001\n","INFO:tensorflow:global_step/sec: 86.3159\n","INFO:tensorflow:loss = 10.662354, step = 25101 (1.166 sec)\n","INFO:tensorflow:global_step/sec: 99.9679\n","INFO:tensorflow:loss = 13.283706, step = 25201 (1.000 sec)\n","INFO:tensorflow:global_step/sec: 93.2086\n","INFO:tensorflow:loss = 9.235025, step = 25301 (1.072 sec)\n","INFO:tensorflow:global_step/sec: 101.709\n","INFO:tensorflow:loss = 12.197973, step = 25401 (0.980 sec)\n","INFO:tensorflow:global_step/sec: 94.2296\n","INFO:tensorflow:loss = 20.799212, step = 25501 (1.060 sec)\n","INFO:tensorflow:global_step/sec: 98.7488\n","INFO:tensorflow:loss = 8.53719, step = 25601 (1.016 sec)\n","INFO:tensorflow:global_step/sec: 98.0709\n","INFO:tensorflow:loss = 9.405827, step = 25701 (1.019 sec)\n","INFO:tensorflow:global_step/sec: 93.2332\n","INFO:tensorflow:loss = 12.456976, step = 25801 (1.074 sec)\n","INFO:tensorflow:global_step/sec: 99.7993\n","INFO:tensorflow:loss = 12.917614, step = 25901 (1.000 sec)\n","INFO:tensorflow:global_step/sec: 96.8374\n","INFO:tensorflow:loss = 11.199167, step = 26001 (1.036 sec)\n","INFO:tensorflow:global_step/sec: 101.482\n","INFO:tensorflow:loss = 15.298016, step = 26101 (0.985 sec)\n","INFO:tensorflow:global_step/sec: 102.396\n","INFO:tensorflow:loss = 14.733105, step = 26201 (0.976 sec)\n","INFO:tensorflow:global_step/sec: 97.7165\n","INFO:tensorflow:loss = 12.290565, step = 26301 (1.025 sec)\n","INFO:tensorflow:global_step/sec: 101.587\n","INFO:tensorflow:loss = 11.001206, step = 26401 (0.982 sec)\n","INFO:tensorflow:global_step/sec: 93.6167\n","INFO:tensorflow:loss = 14.47353, step = 26501 (1.070 sec)\n","INFO:tensorflow:global_step/sec: 97.8382\n","INFO:tensorflow:loss = 16.310299, step = 26601 (1.024 sec)\n","INFO:tensorflow:global_step/sec: 99.9943\n","INFO:tensorflow:loss = 18.257133, step = 26701 (0.999 sec)\n","INFO:tensorflow:global_step/sec: 97.7092\n","INFO:tensorflow:loss = 19.859673, step = 26801 (1.025 sec)\n","INFO:tensorflow:global_step/sec: 100.889\n","INFO:tensorflow:loss = 14.061874, step = 26901 (0.988 sec)\n","INFO:tensorflow:global_step/sec: 92.7193\n","INFO:tensorflow:loss = 12.16392, step = 27001 (1.080 sec)\n","INFO:tensorflow:global_step/sec: 96.7769\n","INFO:tensorflow:loss = 12.388816, step = 27101 (1.028 sec)\n","INFO:tensorflow:global_step/sec: 97.4251\n","INFO:tensorflow:loss = 13.556815, step = 27201 (1.028 sec)\n","INFO:tensorflow:global_step/sec: 94.3419\n","INFO:tensorflow:loss = 8.850932, step = 27301 (1.059 sec)\n","INFO:tensorflow:global_step/sec: 103.381\n","INFO:tensorflow:loss = 14.129996, step = 27401 (0.972 sec)\n","INFO:tensorflow:global_step/sec: 96.5908\n","INFO:tensorflow:loss = 12.38148, step = 27501 (1.034 sec)\n","INFO:tensorflow:global_step/sec: 101.344\n","INFO:tensorflow:loss = 14.052695, step = 27601 (0.983 sec)\n","INFO:tensorflow:global_step/sec: 102.057\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 12.696263, step = 27701 (0.984 sec)\n","INFO:tensorflow:global_step/sec: 95.9778\n","INFO:tensorflow:loss = 12.934294, step = 27801 (1.039 sec)\n","INFO:tensorflow:global_step/sec: 98.8993\n","INFO:tensorflow:loss = 22.311693, step = 27901 (1.015 sec)\n","INFO:tensorflow:global_step/sec: 94.8601\n","INFO:tensorflow:loss = 12.547639, step = 28001 (1.057 sec)\n","INFO:tensorflow:global_step/sec: 101.066\n","INFO:tensorflow:loss = 12.534594, step = 28101 (0.982 sec)\n","INFO:tensorflow:global_step/sec: 101.325\n","INFO:tensorflow:loss = 17.97015, step = 28201 (0.990 sec)\n","INFO:tensorflow:global_step/sec: 97.1645\n","INFO:tensorflow:loss = 23.35914, step = 28301 (1.028 sec)\n","INFO:tensorflow:global_step/sec: 102.624\n","INFO:tensorflow:loss = 10.807907, step = 28401 (0.973 sec)\n","INFO:tensorflow:global_step/sec: 94.1638\n","INFO:tensorflow:loss = 18.282154, step = 28501 (1.065 sec)\n","INFO:tensorflow:global_step/sec: 101.519\n","INFO:tensorflow:loss = 17.378416, step = 28601 (0.982 sec)\n","INFO:tensorflow:global_step/sec: 100.841\n","INFO:tensorflow:loss = 15.019831, step = 28701 (0.994 sec)\n","INFO:tensorflow:global_step/sec: 93.3947\n","INFO:tensorflow:loss = 9.244625, step = 28801 (1.071 sec)\n","INFO:tensorflow:global_step/sec: 102.78\n","INFO:tensorflow:loss = 10.944618, step = 28901 (0.970 sec)\n","INFO:tensorflow:global_step/sec: 96.867\n","INFO:tensorflow:loss = 13.353834, step = 29001 (1.034 sec)\n","INFO:tensorflow:global_step/sec: 100.917\n","INFO:tensorflow:loss = 12.594349, step = 29101 (0.990 sec)\n","INFO:tensorflow:global_step/sec: 102.315\n","INFO:tensorflow:loss = 12.043217, step = 29201 (0.977 sec)\n","INFO:tensorflow:global_step/sec: 97.4296\n","INFO:tensorflow:loss = 10.446644, step = 29301 (1.029 sec)\n","INFO:tensorflow:global_step/sec: 102.228\n","INFO:tensorflow:loss = 14.572644, step = 29401 (0.978 sec)\n","INFO:tensorflow:global_step/sec: 98.0716\n","INFO:tensorflow:loss = 7.929666, step = 29501 (1.022 sec)\n","INFO:tensorflow:global_step/sec: 101.202\n","INFO:tensorflow:loss = 10.713306, step = 29601 (0.982 sec)\n","INFO:tensorflow:global_step/sec: 101.325\n","INFO:tensorflow:loss = 12.500353, step = 29701 (0.991 sec)\n","INFO:tensorflow:global_step/sec: 97.6878\n","INFO:tensorflow:loss = 7.316613, step = 29801 (1.023 sec)\n","INFO:tensorflow:global_step/sec: 102.608\n","INFO:tensorflow:loss = 13.944964, step = 29901 (0.976 sec)\n","INFO:tensorflow:global_step/sec: 95.2206\n","INFO:tensorflow:loss = 15.300351, step = 30001 (1.048 sec)\n","INFO:tensorflow:global_step/sec: 101.8\n","INFO:tensorflow:loss = 8.421698, step = 30101 (0.984 sec)\n","INFO:tensorflow:global_step/sec: 102.813\n","INFO:tensorflow:loss = 7.4695444, step = 30201 (0.970 sec)\n","INFO:tensorflow:global_step/sec: 97.3694\n","INFO:tensorflow:loss = 12.555986, step = 30301 (1.028 sec)\n","INFO:tensorflow:global_step/sec: 104.515\n","INFO:tensorflow:loss = 13.741392, step = 30401 (0.953 sec)\n","INFO:tensorflow:global_step/sec: 97.2223\n","INFO:tensorflow:loss = 10.177872, step = 30501 (1.037 sec)\n","INFO:tensorflow:global_step/sec: 101.936\n","INFO:tensorflow:loss = 16.748383, step = 30601 (0.979 sec)\n","INFO:tensorflow:global_step/sec: 103.248\n","INFO:tensorflow:loss = 10.512478, step = 30701 (0.966 sec)\n","INFO:tensorflow:global_step/sec: 98.0439\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 9.88643, step = 30801 (1.022 sec)\n","INFO:tensorflow:global_step/sec: 98.7534\n","INFO:tensorflow:loss = 8.357811, step = 30901 (1.011 sec)\n","INFO:tensorflow:global_step/sec: 95.1246\n","INFO:tensorflow:loss = 10.042503, step = 31001 (1.055 sec)\n","INFO:tensorflow:global_step/sec: 99.9177\n","INFO:tensorflow:loss = 10.764622, step = 31101 (1.001 sec)\n","INFO:tensorflow:global_step/sec: 102.22\n","INFO:tensorflow:loss = 17.408222, step = 31201 (0.977 sec)\n","INFO:tensorflow:global_step/sec: 98.0733\n","INFO:tensorflow:loss = 11.7170315, step = 31301 (1.017 sec)\n","INFO:tensorflow:global_step/sec: 103.595\n","INFO:tensorflow:loss = 9.104362, step = 31401 (0.965 sec)\n","INFO:tensorflow:global_step/sec: 97.0054\n","INFO:tensorflow:loss = 11.384176, step = 31501 (1.032 sec)\n","INFO:tensorflow:global_step/sec: 101.319\n","INFO:tensorflow:loss = 17.456465, step = 31601 (0.988 sec)\n","INFO:tensorflow:global_step/sec: 102.113\n","INFO:tensorflow:loss = 13.090395, step = 31701 (0.980 sec)\n","INFO:tensorflow:global_step/sec: 96.2499\n","INFO:tensorflow:loss = 17.31981, step = 31801 (1.036 sec)\n","INFO:tensorflow:global_step/sec: 102.781\n","INFO:tensorflow:loss = 12.265793, step = 31901 (0.970 sec)\n","INFO:tensorflow:global_step/sec: 96.8972\n","INFO:tensorflow:loss = 16.945335, step = 32001 (1.033 sec)\n","INFO:tensorflow:global_step/sec: 102.972\n","INFO:tensorflow:loss = 10.467265, step = 32101 (0.970 sec)\n","INFO:tensorflow:global_step/sec: 101.268\n","INFO:tensorflow:loss = 4.604809, step = 32201 (0.988 sec)\n","INFO:tensorflow:global_step/sec: 95.1758\n","INFO:tensorflow:loss = 7.9981074, step = 32301 (1.052 sec)\n","INFO:tensorflow:global_step/sec: 100.693\n","INFO:tensorflow:loss = 17.670296, step = 32401 (0.995 sec)\n","INFO:tensorflow:global_step/sec: 94.9261\n","INFO:tensorflow:loss = 18.04689, step = 32501 (1.051 sec)\n","INFO:tensorflow:global_step/sec: 104.252\n","INFO:tensorflow:loss = 18.668928, step = 32601 (0.961 sec)\n","INFO:tensorflow:global_step/sec: 102.443\n","INFO:tensorflow:loss = 29.67777, step = 32701 (0.975 sec)\n","INFO:tensorflow:global_step/sec: 98.8806\n","INFO:tensorflow:loss = 13.330486, step = 32801 (1.011 sec)\n","INFO:tensorflow:global_step/sec: 102.847\n","INFO:tensorflow:loss = 14.35105, step = 32901 (0.969 sec)\n","INFO:tensorflow:global_step/sec: 98.061\n","INFO:tensorflow:loss = 8.526234, step = 33001 (1.023 sec)\n","INFO:tensorflow:global_step/sec: 102.515\n","INFO:tensorflow:loss = 14.181443, step = 33101 (0.975 sec)\n","INFO:tensorflow:global_step/sec: 103.287\n","INFO:tensorflow:loss = 15.788053, step = 33201 (0.972 sec)\n","INFO:tensorflow:global_step/sec: 97.9968\n","INFO:tensorflow:loss = 11.055578, step = 33301 (1.016 sec)\n","INFO:tensorflow:global_step/sec: 103.307\n","INFO:tensorflow:loss = 15.609051, step = 33401 (0.970 sec)\n","INFO:tensorflow:global_step/sec: 98.0488\n","INFO:tensorflow:loss = 13.9969635, step = 33501 (1.023 sec)\n","INFO:tensorflow:global_step/sec: 102.545\n","INFO:tensorflow:loss = 9.813056, step = 33601 (0.969 sec)\n","INFO:tensorflow:global_step/sec: 101.754\n","INFO:tensorflow:loss = 15.5060215, step = 33701 (0.985 sec)\n","INFO:tensorflow:global_step/sec: 95.7416\n","INFO:tensorflow:loss = 11.272133, step = 33801 (1.047 sec)\n","INFO:tensorflow:global_step/sec: 101.114\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 13.726539, step = 33901 (0.990 sec)\n","INFO:tensorflow:global_step/sec: 96.83\n","INFO:tensorflow:loss = 9.614839, step = 34001 (1.028 sec)\n","INFO:tensorflow:global_step/sec: 102.661\n","INFO:tensorflow:loss = 12.129532, step = 34101 (0.974 sec)\n","INFO:tensorflow:global_step/sec: 98.6151\n","INFO:tensorflow:loss = 11.320404, step = 34201 (1.018 sec)\n","INFO:tensorflow:global_step/sec: 95.663\n","INFO:tensorflow:loss = 12.0426655, step = 34301 (1.047 sec)\n","INFO:tensorflow:global_step/sec: 101.882\n","INFO:tensorflow:loss = 18.685858, step = 34401 (0.983 sec)\n","INFO:tensorflow:global_step/sec: 95.8554\n","INFO:tensorflow:loss = 11.165781, step = 34501 (1.041 sec)\n","INFO:tensorflow:global_step/sec: 100.93\n","INFO:tensorflow:loss = 12.803057, step = 34601 (0.987 sec)\n","INFO:tensorflow:global_step/sec: 104.954\n","INFO:tensorflow:loss = 11.701266, step = 34701 (0.957 sec)\n","INFO:tensorflow:global_step/sec: 96.3374\n","INFO:tensorflow:loss = 24.852287, step = 34801 (1.037 sec)\n","INFO:tensorflow:global_step/sec: 104.428\n","INFO:tensorflow:loss = 13.311176, step = 34901 (0.958 sec)\n","INFO:tensorflow:global_step/sec: 98.9142\n","INFO:tensorflow:loss = 13.91603, step = 35001 (1.011 sec)\n","INFO:tensorflow:global_step/sec: 102.149\n","INFO:tensorflow:loss = 15.444044, step = 35101 (0.977 sec)\n","INFO:tensorflow:global_step/sec: 104.59\n","INFO:tensorflow:loss = 16.154942, step = 35201 (0.957 sec)\n","INFO:tensorflow:global_step/sec: 99.8877\n","INFO:tensorflow:loss = 15.55877, step = 35301 (1.002 sec)\n","INFO:tensorflow:global_step/sec: 102.493\n","INFO:tensorflow:loss = 16.445137, step = 35401 (0.973 sec)\n","INFO:tensorflow:global_step/sec: 95.6991\n","INFO:tensorflow:loss = 10.894584, step = 35501 (1.041 sec)\n","INFO:tensorflow:global_step/sec: 104.045\n","INFO:tensorflow:loss = 12.760887, step = 35601 (0.965 sec)\n","INFO:tensorflow:global_step/sec: 102.755\n","INFO:tensorflow:loss = 21.133583, step = 35701 (0.969 sec)\n","INFO:tensorflow:global_step/sec: 98.1894\n","INFO:tensorflow:loss = 10.822594, step = 35801 (1.024 sec)\n","INFO:tensorflow:global_step/sec: 102.609\n","INFO:tensorflow:loss = 12.203684, step = 35901 (0.975 sec)\n","INFO:tensorflow:global_step/sec: 98.2371\n","INFO:tensorflow:loss = 8.924161, step = 36001 (1.019 sec)\n","INFO:tensorflow:global_step/sec: 99.5915\n","INFO:tensorflow:loss = 17.184824, step = 36101 (1.001 sec)\n","INFO:tensorflow:global_step/sec: 103.629\n","INFO:tensorflow:loss = 12.543932, step = 36201 (0.965 sec)\n","INFO:tensorflow:global_step/sec: 94.6129\n","INFO:tensorflow:loss = 14.686011, step = 36301 (1.057 sec)\n","INFO:tensorflow:global_step/sec: 102.19\n","INFO:tensorflow:loss = 16.666622, step = 36401 (0.982 sec)\n","INFO:tensorflow:global_step/sec: 97.9324\n","INFO:tensorflow:loss = 7.618296, step = 36501 (1.019 sec)\n","INFO:tensorflow:global_step/sec: 104.398\n","INFO:tensorflow:loss = 11.706437, step = 36601 (0.961 sec)\n","INFO:tensorflow:global_step/sec: 102.779\n","INFO:tensorflow:loss = 11.261192, step = 36701 (0.969 sec)\n","INFO:tensorflow:global_step/sec: 99.4004\n","INFO:tensorflow:loss = 19.3619, step = 36801 (1.008 sec)\n","INFO:tensorflow:global_step/sec: 101.795\n","INFO:tensorflow:loss = 12.926572, step = 36901 (0.983 sec)\n","INFO:tensorflow:global_step/sec: 97.5041\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 9.5090275, step = 37001 (1.025 sec)\n","INFO:tensorflow:global_step/sec: 104.263\n","INFO:tensorflow:loss = 14.340878, step = 37101 (0.962 sec)\n","INFO:tensorflow:global_step/sec: 101.666\n","INFO:tensorflow:loss = 9.564837, step = 37201 (0.980 sec)\n","INFO:tensorflow:global_step/sec: 95.9073\n","INFO:tensorflow:loss = 9.033941, step = 37301 (1.038 sec)\n","INFO:tensorflow:global_step/sec: 105.326\n","INFO:tensorflow:loss = 13.71686, step = 37401 (0.953 sec)\n","INFO:tensorflow:global_step/sec: 95.2762\n","INFO:tensorflow:loss = 15.6574745, step = 37501 (1.053 sec)\n","INFO:tensorflow:global_step/sec: 102.262\n","INFO:tensorflow:loss = 13.846524, step = 37601 (0.975 sec)\n","INFO:tensorflow:global_step/sec: 105.139\n","INFO:tensorflow:loss = 10.723954, step = 37701 (0.950 sec)\n","INFO:tensorflow:global_step/sec: 95.2089\n","INFO:tensorflow:loss = 15.423489, step = 37801 (1.051 sec)\n","INFO:tensorflow:global_step/sec: 99.4411\n","INFO:tensorflow:loss = 13.620139, step = 37901 (1.008 sec)\n","INFO:tensorflow:global_step/sec: 98.7285\n","INFO:tensorflow:loss = 15.276685, step = 38001 (1.014 sec)\n","INFO:tensorflow:global_step/sec: 103.133\n","INFO:tensorflow:loss = 19.179823, step = 38101 (0.966 sec)\n","INFO:tensorflow:global_step/sec: 104.135\n","INFO:tensorflow:loss = 12.00224, step = 38201 (0.963 sec)\n","INFO:tensorflow:global_step/sec: 98.1535\n","INFO:tensorflow:loss = 11.491089, step = 38301 (1.022 sec)\n","INFO:tensorflow:global_step/sec: 103.674\n","INFO:tensorflow:loss = 12.677735, step = 38401 (0.964 sec)\n","INFO:tensorflow:global_step/sec: 94.6084\n","INFO:tensorflow:loss = 9.076782, step = 38501 (1.051 sec)\n","INFO:tensorflow:global_step/sec: 101.862\n","INFO:tensorflow:loss = 9.924115, step = 38601 (0.986 sec)\n","INFO:tensorflow:global_step/sec: 101.964\n","INFO:tensorflow:loss = 9.861393, step = 38701 (0.981 sec)\n","INFO:tensorflow:global_step/sec: 98.0393\n","INFO:tensorflow:loss = 12.106282, step = 38801 (1.018 sec)\n","INFO:tensorflow:global_step/sec: 99.6109\n","INFO:tensorflow:loss = 17.631092, step = 38901 (1.006 sec)\n","INFO:tensorflow:global_step/sec: 97.9172\n","INFO:tensorflow:loss = 8.256972, step = 39001 (1.021 sec)\n","INFO:tensorflow:global_step/sec: 103.982\n","INFO:tensorflow:loss = 11.8522835, step = 39101 (0.961 sec)\n","INFO:tensorflow:global_step/sec: 104.124\n","INFO:tensorflow:loss = 12.080112, step = 39201 (0.961 sec)\n","INFO:tensorflow:global_step/sec: 96.578\n","INFO:tensorflow:loss = 23.125294, step = 39301 (1.031 sec)\n","INFO:tensorflow:global_step/sec: 102.456\n","INFO:tensorflow:loss = 17.312332, step = 39401 (0.974 sec)\n","INFO:tensorflow:global_step/sec: 99.2382\n","INFO:tensorflow:loss = 12.0238, step = 39501 (1.015 sec)\n","INFO:tensorflow:global_step/sec: 102.647\n","INFO:tensorflow:loss = 15.687769, step = 39601 (0.970 sec)\n","INFO:tensorflow:global_step/sec: 99.3788\n","INFO:tensorflow:loss = 12.123222, step = 39701 (1.003 sec)\n","INFO:tensorflow:global_step/sec: 95.4635\n","INFO:tensorflow:loss = 12.507872, step = 39801 (1.051 sec)\n","INFO:tensorflow:global_step/sec: 103.87\n","INFO:tensorflow:loss = 14.88863, step = 39901 (0.964 sec)\n","INFO:tensorflow:global_step/sec: 94.6735\n","INFO:tensorflow:loss = 12.516601, step = 40001 (1.055 sec)\n","INFO:tensorflow:global_step/sec: 102.091\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 11.075054, step = 40101 (0.982 sec)\n","INFO:tensorflow:global_step/sec: 102.954\n","INFO:tensorflow:loss = 7.379535, step = 40201 (0.969 sec)\n","INFO:tensorflow:global_step/sec: 96.328\n","INFO:tensorflow:loss = 16.798708, step = 40301 (1.038 sec)\n","INFO:tensorflow:global_step/sec: 100.753\n","INFO:tensorflow:loss = 9.812967, step = 40401 (0.993 sec)\n","INFO:tensorflow:global_step/sec: 93.742\n","INFO:tensorflow:loss = 8.502751, step = 40501 (1.070 sec)\n","INFO:tensorflow:global_step/sec: 101.842\n","INFO:tensorflow:loss = 8.113275, step = 40601 (0.981 sec)\n","INFO:tensorflow:global_step/sec: 104.054\n","INFO:tensorflow:loss = 5.8472333, step = 40701 (0.960 sec)\n","INFO:tensorflow:global_step/sec: 100.028\n","INFO:tensorflow:loss = 25.973793, step = 40801 (0.997 sec)\n","INFO:tensorflow:global_step/sec: 101.243\n","INFO:tensorflow:loss = 12.248131, step = 40901 (0.992 sec)\n","INFO:tensorflow:global_step/sec: 96.7195\n","INFO:tensorflow:loss = 13.6638155, step = 41001 (1.027 sec)\n","INFO:tensorflow:global_step/sec: 101.806\n","INFO:tensorflow:loss = 10.449759, step = 41101 (0.989 sec)\n","INFO:tensorflow:global_step/sec: 102.305\n","INFO:tensorflow:loss = 13.86372, step = 41201 (0.977 sec)\n","INFO:tensorflow:global_step/sec: 97.4234\n","INFO:tensorflow:loss = 10.989154, step = 41301 (1.027 sec)\n","INFO:tensorflow:global_step/sec: 103.095\n","INFO:tensorflow:loss = 12.090939, step = 41401 (0.964 sec)\n","INFO:tensorflow:global_step/sec: 93.4055\n","INFO:tensorflow:loss = 15.807845, step = 41501 (1.077 sec)\n","INFO:tensorflow:global_step/sec: 103.541\n","INFO:tensorflow:loss = 16.902084, step = 41601 (0.963 sec)\n","INFO:tensorflow:global_step/sec: 104.38\n","INFO:tensorflow:loss = 19.771183, step = 41701 (0.959 sec)\n","INFO:tensorflow:global_step/sec: 97.2254\n","INFO:tensorflow:loss = 10.570041, step = 41801 (1.026 sec)\n","INFO:tensorflow:global_step/sec: 102.3\n","INFO:tensorflow:loss = 11.4399, step = 41901 (0.982 sec)\n","INFO:tensorflow:global_step/sec: 98.159\n","INFO:tensorflow:loss = 18.95197, step = 42001 (1.019 sec)\n","INFO:tensorflow:global_step/sec: 101.852\n","INFO:tensorflow:loss = 9.636667, step = 42101 (0.979 sec)\n","INFO:tensorflow:global_step/sec: 103.396\n","INFO:tensorflow:loss = 11.060336, step = 42201 (0.966 sec)\n","INFO:tensorflow:global_step/sec: 99.0509\n","INFO:tensorflow:loss = 19.416304, step = 42301 (1.011 sec)\n","INFO:tensorflow:global_step/sec: 103.531\n","INFO:tensorflow:loss = 11.24602, step = 42401 (0.966 sec)\n","INFO:tensorflow:global_step/sec: 98.7944\n","INFO:tensorflow:loss = 12.700331, step = 42501 (1.014 sec)\n","INFO:tensorflow:global_step/sec: 103.831\n","INFO:tensorflow:loss = 7.6146126, step = 42601 (0.963 sec)\n","INFO:tensorflow:global_step/sec: 103.43\n","INFO:tensorflow:loss = 11.77263, step = 42701 (0.967 sec)\n","INFO:tensorflow:global_step/sec: 96.5804\n","INFO:tensorflow:loss = 18.49202, step = 42801 (1.028 sec)\n","INFO:tensorflow:global_step/sec: 104.864\n","INFO:tensorflow:loss = 22.135824, step = 42901 (0.959 sec)\n","INFO:tensorflow:global_step/sec: 95.3228\n","INFO:tensorflow:loss = 9.170792, step = 43001 (1.047 sec)\n","INFO:tensorflow:global_step/sec: 102.685\n","INFO:tensorflow:loss = 16.376244, step = 43101 (0.974 sec)\n","INFO:tensorflow:global_step/sec: 104.696\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 16.006056, step = 43201 (0.952 sec)\n","INFO:tensorflow:global_step/sec: 97.1896\n","INFO:tensorflow:loss = 10.104688, step = 43301 (1.035 sec)\n","INFO:tensorflow:global_step/sec: 102.443\n","INFO:tensorflow:loss = 15.093405, step = 43401 (0.973 sec)\n","INFO:tensorflow:global_step/sec: 96.1546\n","INFO:tensorflow:loss = 9.640521, step = 43501 (1.043 sec)\n","INFO:tensorflow:global_step/sec: 102.053\n","INFO:tensorflow:loss = 10.241702, step = 43601 (0.977 sec)\n","INFO:tensorflow:global_step/sec: 100.41\n","INFO:tensorflow:loss = 24.894825, step = 43701 (0.996 sec)\n","INFO:tensorflow:global_step/sec: 97.6055\n","INFO:tensorflow:loss = 11.63529, step = 43801 (1.027 sec)\n","INFO:tensorflow:global_step/sec: 102.216\n","INFO:tensorflow:loss = 21.117136, step = 43901 (0.979 sec)\n","INFO:tensorflow:global_step/sec: 95.6342\n","INFO:tensorflow:loss = 9.5882015, step = 44001 (1.045 sec)\n","INFO:tensorflow:global_step/sec: 99.3788\n","INFO:tensorflow:loss = 12.963087, step = 44101 (1.004 sec)\n","INFO:tensorflow:global_step/sec: 101.606\n","INFO:tensorflow:loss = 14.529823, step = 44201 (0.983 sec)\n","INFO:tensorflow:global_step/sec: 96.797\n","INFO:tensorflow:loss = 13.339327, step = 44301 (1.036 sec)\n","INFO:tensorflow:global_step/sec: 105.658\n","INFO:tensorflow:loss = 11.569784, step = 44401 (0.947 sec)\n","INFO:tensorflow:global_step/sec: 97.6093\n","INFO:tensorflow:loss = 12.372918, step = 44501 (1.022 sec)\n","INFO:tensorflow:global_step/sec: 102.383\n","INFO:tensorflow:loss = 8.666291, step = 44601 (0.979 sec)\n","INFO:tensorflow:global_step/sec: 103.059\n","INFO:tensorflow:loss = 11.876488, step = 44701 (0.971 sec)\n","INFO:tensorflow:global_step/sec: 96.271\n","INFO:tensorflow:loss = 10.543016, step = 44801 (1.037 sec)\n","INFO:tensorflow:global_step/sec: 98.2922\n","INFO:tensorflow:loss = 16.703924, step = 44901 (1.018 sec)\n","INFO:tensorflow:global_step/sec: 97.7276\n","INFO:tensorflow:loss = 7.0728297, step = 45001 (1.024 sec)\n","INFO:tensorflow:global_step/sec: 103.909\n","INFO:tensorflow:loss = 9.823458, step = 45101 (0.960 sec)\n","INFO:tensorflow:global_step/sec: 100.356\n","INFO:tensorflow:loss = 17.78128, step = 45201 (0.998 sec)\n","INFO:tensorflow:global_step/sec: 99.6415\n","INFO:tensorflow:loss = 14.110541, step = 45301 (1.005 sec)\n","INFO:tensorflow:global_step/sec: 103.087\n","INFO:tensorflow:loss = 12.449866, step = 45401 (0.967 sec)\n","INFO:tensorflow:global_step/sec: 95.3829\n","INFO:tensorflow:loss = 14.849502, step = 45501 (1.047 sec)\n","INFO:tensorflow:global_step/sec: 102.169\n","INFO:tensorflow:loss = 18.572796, step = 45601 (0.979 sec)\n","INFO:tensorflow:global_step/sec: 101.626\n","INFO:tensorflow:loss = 14.56025, step = 45701 (0.986 sec)\n","INFO:tensorflow:global_step/sec: 94.5777\n","INFO:tensorflow:loss = 13.674651, step = 45801 (1.059 sec)\n","INFO:tensorflow:global_step/sec: 100.774\n","INFO:tensorflow:loss = 8.037812, step = 45901 (0.987 sec)\n","INFO:tensorflow:global_step/sec: 95.6935\n","INFO:tensorflow:loss = 13.724473, step = 46001 (1.051 sec)\n","INFO:tensorflow:global_step/sec: 102.23\n","INFO:tensorflow:loss = 8.818345, step = 46101 (0.979 sec)\n","INFO:tensorflow:global_step/sec: 101.995\n","INFO:tensorflow:loss = 13.482515, step = 46201 (0.978 sec)\n","INFO:tensorflow:global_step/sec: 95.1466\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 10.436016, step = 46301 (1.049 sec)\n","INFO:tensorflow:global_step/sec: 96.224\n","INFO:tensorflow:loss = 10.549406, step = 46401 (1.042 sec)\n","INFO:tensorflow:global_step/sec: 94.9679\n","INFO:tensorflow:loss = 17.077265, step = 46501 (1.054 sec)\n","INFO:tensorflow:global_step/sec: 102.09\n","INFO:tensorflow:loss = 12.405507, step = 46601 (0.977 sec)\n","INFO:tensorflow:global_step/sec: 100.97\n","INFO:tensorflow:loss = 11.432415, step = 46701 (0.991 sec)\n","INFO:tensorflow:global_step/sec: 98.6488\n","INFO:tensorflow:loss = 20.436565, step = 46801 (1.013 sec)\n","INFO:tensorflow:global_step/sec: 102.673\n","INFO:tensorflow:loss = 10.999123, step = 46901 (0.976 sec)\n","INFO:tensorflow:global_step/sec: 91.316\n","INFO:tensorflow:loss = 25.630232, step = 47001 (1.098 sec)\n","INFO:tensorflow:global_step/sec: 103.752\n","INFO:tensorflow:loss = 10.310703, step = 47101 (0.960 sec)\n","INFO:tensorflow:global_step/sec: 102.517\n","INFO:tensorflow:loss = 13.733614, step = 47201 (0.975 sec)\n","INFO:tensorflow:global_step/sec: 97.385\n","INFO:tensorflow:loss = 10.088022, step = 47301 (1.024 sec)\n","INFO:tensorflow:global_step/sec: 104.566\n","INFO:tensorflow:loss = 20.204771, step = 47401 (0.956 sec)\n","INFO:tensorflow:global_step/sec: 98.0431\n","INFO:tensorflow:loss = 15.361049, step = 47501 (1.019 sec)\n","INFO:tensorflow:global_step/sec: 103.874\n","INFO:tensorflow:loss = 10.62916, step = 47601 (0.968 sec)\n","INFO:tensorflow:global_step/sec: 102.986\n","INFO:tensorflow:loss = 10.053626, step = 47701 (0.972 sec)\n","INFO:tensorflow:global_step/sec: 96.3007\n","INFO:tensorflow:loss = 9.707368, step = 47801 (1.033 sec)\n","INFO:tensorflow:global_step/sec: 99.8094\n","INFO:tensorflow:loss = 20.255257, step = 47901 (1.008 sec)\n","INFO:tensorflow:global_step/sec: 98.4873\n","INFO:tensorflow:loss = 9.343684, step = 48001 (1.012 sec)\n","INFO:tensorflow:global_step/sec: 104.878\n","INFO:tensorflow:loss = 9.802124, step = 48101 (0.955 sec)\n","INFO:tensorflow:global_step/sec: 102.502\n","INFO:tensorflow:loss = 10.889523, step = 48201 (0.971 sec)\n","INFO:tensorflow:global_step/sec: 98.3187\n","INFO:tensorflow:loss = 13.515037, step = 48301 (1.021 sec)\n","INFO:tensorflow:global_step/sec: 102.329\n","INFO:tensorflow:loss = 15.554086, step = 48401 (0.981 sec)\n","INFO:tensorflow:global_step/sec: 94.7815\n","INFO:tensorflow:loss = 17.10781, step = 48501 (1.052 sec)\n","INFO:tensorflow:global_step/sec: 104.886\n","INFO:tensorflow:loss = 13.796553, step = 48601 (0.955 sec)\n","INFO:tensorflow:global_step/sec: 103.459\n","INFO:tensorflow:loss = 14.827267, step = 48701 (0.965 sec)\n","INFO:tensorflow:global_step/sec: 95.7917\n","INFO:tensorflow:loss = 9.858277, step = 48801 (1.041 sec)\n","INFO:tensorflow:global_step/sec: 100.836\n","INFO:tensorflow:loss = 11.137138, step = 48901 (0.990 sec)\n","INFO:tensorflow:global_step/sec: 95.7344\n","INFO:tensorflow:loss = 12.367629, step = 49001 (1.050 sec)\n","INFO:tensorflow:global_step/sec: 101.265\n","INFO:tensorflow:loss = 19.776628, step = 49101 (0.988 sec)\n","INFO:tensorflow:global_step/sec: 105.559\n","INFO:tensorflow:loss = 15.38045, step = 49201 (0.947 sec)\n","INFO:tensorflow:global_step/sec: 96.5036\n","INFO:tensorflow:loss = 12.292949, step = 49301 (1.032 sec)\n","INFO:tensorflow:global_step/sec: 98.8778\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 11.774881, step = 49401 (1.013 sec)\n","INFO:tensorflow:global_step/sec: 97.0575\n","INFO:tensorflow:loss = 9.3643055, step = 49501 (1.034 sec)\n","INFO:tensorflow:global_step/sec: 103.299\n","INFO:tensorflow:loss = 18.232077, step = 49601 (0.964 sec)\n","INFO:tensorflow:global_step/sec: 101.462\n","INFO:tensorflow:loss = 12.102097, step = 49701 (0.985 sec)\n","INFO:tensorflow:global_step/sec: 98.7084\n","INFO:tensorflow:loss = 10.233621, step = 49801 (1.011 sec)\n","INFO:tensorflow:global_step/sec: 102.964\n","INFO:tensorflow:loss = 16.773083, step = 49901 (0.975 sec)\n","INFO:tensorflow:Saving checkpoints for 50000 into /tmp/tmpj4vob2jo/bow_sparse/model.ckpt.\n","INFO:tensorflow:Loss for final step: 13.966096.\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2018-04-09-11:56:25\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpj4vob2jo/bow_sparse/model.ckpt-50000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Finished evaluation at 2018-04-09-11:56:28\n","INFO:tensorflow:Saving dict for global step 50000: accuracy = 0.81116, accuracy_baseline = 0.5, auc = 0.8819076, auc_precision_recall = 0.8848152, average_loss = 0.771712, global_step = 50000, label/mean = 0.5, loss = 77.1712, prediction/mean = 0.48115262\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpj4vob2jo/bow_sparse/model.ckpt-50000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"}]},{"metadata":{"id":"_qAHrTDbvq99","colab_type":"text"},"cell_type":"markdown","source":["One of the benefits of choosing a simple model is that it's much more inspectable. The more complex the model is, the more it tends to work like a black box. In this example we can load the weights from our model's last checkpoint and take a look at what tokens correspond to the  biggest weights in absolute value. The results looks like what we would expect"]},{"metadata":{"id":"R7iy_8MAvq9-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":407},"outputId":"2eaeb25d-7f32-4ceb-c676-c6ef8093324a","executionInfo":{"status":"ok","timestamp":1523274052541,"user_tz":180,"elapsed":1098,"user":{"displayName":"Julian Eisenschlos","photoUrl":"//lh3.googleusercontent.com/-64ZxueD_a5k/AAAAAAAAAAI/AAAAAAAAY_I/SjD0k9jJ8Ug/s50-c-k-no/photo.jpg","userId":"112692138304087361987"}}},"cell_type":"code","source":["weights = classifier.get_variable_value('linear/linear_model/x/weights').flatten()\n","sorted_indexes = np.argsort(weights)\n","extremes = np.concatenate((sorted_indexes[-8:], sorted_indexes[:8]))\n","extreme_weights = sorted([(weights[i], word_inverted_index[i]) for i in extremes])\n","\n","y_pos = np.arange(len(extreme_weights))\n","plt.bar(y_pos, [pair[0] for pair in extreme_weights], align='center', alpha=0.5)\n","plt.xticks(y_pos, [pair[1] for pair in extreme_weights], rotation=45, ha='right')\n","plt.ylabel('Weight')\n","plt.title('Most significant tokens') \n","plt.show()"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAe0AAAGGCAYAAABWh9liAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA69oToyFyv4TAAAAAElFTkSuQmCC\n","text/plain":["<matplotlib.figure.Figure at 0x7fb4e93cd160>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"5WuKOz3zk9Ip","colab_type":"text"},"cell_type":"markdown","source":["As we can see, tokens with the most positive weight such as 'refreshing' are clearly associated with positive sentiment, while tokens that have a large negative weight unarguably evoke negative emotions. A simple but powerful modification that one can do to improve this model is weighting the tokens by their [tf-idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) scores."]},{"metadata":{"id":"ptorLYCwArTp","colab_type":"text"},"cell_type":"markdown","source":["### Embeddings\n","\n","The next step of complexity we can add are word embeddings. Embeddings are a dense low-dimensional representation of sparse high-dimensional data. This allows our model to learn a more meaningful representation of each token, rather than just an index. While an individual dimension is not meaningful, the low-dimensional space---when learned from a large enough corpus---has been shown to capture relations such as tense, plural, gender, thematic relatedness, and many more. We can add word embeddings by converting our existing feature column into an `embedding_column`. The representation seen by the model is the mean of the embeddings for each token (see the `combiner` argument in the [docs](https://www.tensorflow.org/api_docs/python/tf/feature_column/embedding_column)). We can plug in the embedded features into a pre-canned `DNNClassifier`. \n","\n","A note for the keen observer: an `embedding_column` is just an efficient way of applying a fully connected layer to the sparse binary feature vector of tokens, which is multiplied by a constant depending on the chosen combiner. A direct consequence of this is that it wouldn't make sense to use an `embedding_column` directly in a `LinearClassifier` because two consecutive linear layers without non-linearities in between add no prediction power to the model, unless of course the embeddings are pre-trained."]},{"metadata":{"id":"IpJrW8_zvq-D","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":8979},"outputId":"2d3d6041-1ac3-468e-cd8c-9760c558f30e","executionInfo":{"status":"ok","timestamp":1520355496237,"user_tz":0,"elapsed":274050,"user":{"displayName":"Sebastian Ruder","photoUrl":"//lh5.googleusercontent.com/-_RsKB476gus/AAAAAAAAAAI/AAAAAAAAVys/bDJNFfUAEUU/s50-c-k-no/photo.jpg","userId":"101962136952284559776"}}},"cell_type":"code","source":["word_embedding_column = tf.feature_column.embedding_column(column, dimension=embedding_size)\n","classifier = tf.estimator.DNNClassifier(\n","    hidden_units=[100],\n","    feature_columns=[word_embedding_column], \n","    model_dir=os.path.join(model_dir, 'bow_embeddings'))\n","train_and_evaluate(classifier)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using default config.\n","INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmppw5q4h5g/bow_embeddings', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff80ca4bfd0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmppw5q4h5g/bow_embeddings/model.ckpt-25000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 25001 into /tmp/tmppw5q4h5g/bow_embeddings/model.ckpt.\n","INFO:tensorflow:loss = 0.07225461, step = 25001\n","INFO:tensorflow:global_step/sec: 94.1777\n","INFO:tensorflow:loss = 0.11010328, step = 25101 (1.066 sec)\n","INFO:tensorflow:global_step/sec: 101.045\n","INFO:tensorflow:loss = 0.1038755, step = 25201 (0.992 sec)\n","INFO:tensorflow:global_step/sec: 94.1411\n","INFO:tensorflow:loss = 0.08235868, step = 25301 (1.062 sec)\n","INFO:tensorflow:global_step/sec: 99.9128\n","INFO:tensorflow:loss = 0.12035535, step = 25401 (1.001 sec)\n","INFO:tensorflow:global_step/sec: 91.874\n","INFO:tensorflow:loss = 0.063904524, step = 25501 (1.089 sec)\n","INFO:tensorflow:global_step/sec: 96.8134\n","INFO:tensorflow:loss = 0.08813065, step = 25601 (1.030 sec)\n","INFO:tensorflow:global_step/sec: 99.6714\n","INFO:tensorflow:loss = 0.104998216, step = 25701 (1.007 sec)\n","INFO:tensorflow:global_step/sec: 93.0512\n","INFO:tensorflow:loss = 0.075537436, step = 25801 (1.073 sec)\n","INFO:tensorflow:global_step/sec: 98.3355\n","INFO:tensorflow:loss = 0.13373943, step = 25901 (1.016 sec)\n","INFO:tensorflow:global_step/sec: 92.577\n","INFO:tensorflow:loss = 0.0930696, step = 26001 (1.082 sec)\n","INFO:tensorflow:global_step/sec: 100.805\n","INFO:tensorflow:loss = 0.09760654, step = 26101 (0.990 sec)\n","INFO:tensorflow:global_step/sec: 99.5659\n","INFO:tensorflow:loss = 0.072290905, step = 26201 (1.006 sec)\n","INFO:tensorflow:global_step/sec: 92.5618\n","INFO:tensorflow:loss = 0.07036716, step = 26301 (1.076 sec)\n","INFO:tensorflow:global_step/sec: 98.8033\n","INFO:tensorflow:loss = 0.10850798, step = 26401 (1.014 sec)\n","INFO:tensorflow:global_step/sec: 92.2238\n","INFO:tensorflow:loss = 0.06388406, step = 26501 (1.085 sec)\n","INFO:tensorflow:global_step/sec: 99.8798\n","INFO:tensorflow:loss = 0.10301491, step = 26601 (1.002 sec)\n","INFO:tensorflow:global_step/sec: 99.8437\n","INFO:tensorflow:loss = 0.09297345, step = 26701 (0.997 sec)\n","INFO:tensorflow:global_step/sec: 94.8958\n","INFO:tensorflow:loss = 0.116400495, step = 26801 (1.060 sec)\n","INFO:tensorflow:global_step/sec: 97.6895\n","INFO:tensorflow:loss = 0.07139672, step = 26901 (1.019 sec)\n","INFO:tensorflow:global_step/sec: 93.6707\n","INFO:tensorflow:loss = 0.046116352, step = 27001 (1.071 sec)\n","INFO:tensorflow:global_step/sec: 99.6958\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.045658894, step = 27101 (0.998 sec)\n","INFO:tensorflow:global_step/sec: 99.3092\n","INFO:tensorflow:loss = 0.09517508, step = 27201 (1.011 sec)\n","INFO:tensorflow:global_step/sec: 93.8945\n","INFO:tensorflow:loss = 0.07953494, step = 27301 (1.061 sec)\n","INFO:tensorflow:global_step/sec: 98.8071\n","INFO:tensorflow:loss = 0.099557295, step = 27401 (1.013 sec)\n","INFO:tensorflow:global_step/sec: 94.8515\n","INFO:tensorflow:loss = 0.061936226, step = 27501 (1.059 sec)\n","INFO:tensorflow:global_step/sec: 100.831\n","INFO:tensorflow:loss = 0.095372066, step = 27601 (0.987 sec)\n","INFO:tensorflow:global_step/sec: 99.868\n","INFO:tensorflow:loss = 0.03764773, step = 27701 (1.006 sec)\n","INFO:tensorflow:global_step/sec: 95.4445\n","INFO:tensorflow:loss = 0.040500928, step = 27801 (1.048 sec)\n","INFO:tensorflow:global_step/sec: 99.249\n","INFO:tensorflow:loss = 0.06622554, step = 27901 (1.002 sec)\n","INFO:tensorflow:global_step/sec: 94.1029\n","INFO:tensorflow:loss = 0.056300994, step = 28001 (1.065 sec)\n","INFO:tensorflow:global_step/sec: 97.377\n","INFO:tensorflow:loss = 0.1252041, step = 28101 (1.030 sec)\n","INFO:tensorflow:global_step/sec: 100.556\n","INFO:tensorflow:loss = 0.062389325, step = 28201 (0.993 sec)\n","INFO:tensorflow:global_step/sec: 94.4273\n","INFO:tensorflow:loss = 0.08732199, step = 28301 (1.059 sec)\n","INFO:tensorflow:global_step/sec: 99.5635\n","INFO:tensorflow:loss = 0.036419712, step = 28401 (1.005 sec)\n","INFO:tensorflow:global_step/sec: 94.3595\n","INFO:tensorflow:loss = 0.071163476, step = 28501 (1.054 sec)\n","INFO:tensorflow:global_step/sec: 99.6514\n","INFO:tensorflow:loss = 0.061247613, step = 28601 (1.009 sec)\n","INFO:tensorflow:global_step/sec: 99.9185\n","INFO:tensorflow:loss = 0.0696356, step = 28701 (1.000 sec)\n","INFO:tensorflow:global_step/sec: 94.0037\n","INFO:tensorflow:loss = 0.08004316, step = 28801 (1.063 sec)\n","INFO:tensorflow:global_step/sec: 100.718\n","INFO:tensorflow:loss = 0.08656232, step = 28901 (0.993 sec)\n","INFO:tensorflow:global_step/sec: 94.4897\n","INFO:tensorflow:loss = 0.06049279, step = 29001 (1.058 sec)\n","INFO:tensorflow:global_step/sec: 98.0671\n","INFO:tensorflow:loss = 0.06522488, step = 29101 (1.016 sec)\n","INFO:tensorflow:global_step/sec: 98.963\n","INFO:tensorflow:loss = 0.05935004, step = 29201 (1.014 sec)\n","INFO:tensorflow:global_step/sec: 93.4913\n","INFO:tensorflow:loss = 0.05134121, step = 29301 (1.069 sec)\n","INFO:tensorflow:global_step/sec: 100.713\n","INFO:tensorflow:loss = 0.063985035, step = 29401 (0.994 sec)\n","INFO:tensorflow:global_step/sec: 94.5119\n","INFO:tensorflow:loss = 0.07794091, step = 29501 (1.058 sec)\n","INFO:tensorflow:global_step/sec: 98.2431\n","INFO:tensorflow:loss = 0.06567586, step = 29601 (1.018 sec)\n","INFO:tensorflow:global_step/sec: 99.1044\n","INFO:tensorflow:loss = 0.094307885, step = 29701 (1.010 sec)\n","INFO:tensorflow:global_step/sec: 96.8303\n","INFO:tensorflow:loss = 0.06391385, step = 29801 (1.029 sec)\n","INFO:tensorflow:global_step/sec: 100.894\n","INFO:tensorflow:loss = 0.061641328, step = 29901 (0.995 sec)\n","INFO:tensorflow:global_step/sec: 94.6207\n","INFO:tensorflow:loss = 0.03596317, step = 30001 (1.055 sec)\n","INFO:tensorflow:global_step/sec: 98.1179\n","INFO:tensorflow:loss = 0.05703262, step = 30101 (1.019 sec)\n","INFO:tensorflow:global_step/sec: 102.228\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.07047826, step = 30201 (0.980 sec)\n","INFO:tensorflow:global_step/sec: 94.2099\n","INFO:tensorflow:loss = 0.045549534, step = 30301 (1.063 sec)\n","INFO:tensorflow:global_step/sec: 101.291\n","INFO:tensorflow:loss = 0.09926451, step = 30401 (0.986 sec)\n","INFO:tensorflow:global_step/sec: 93.7017\n","INFO:tensorflow:loss = 0.054343674, step = 30501 (1.065 sec)\n","INFO:tensorflow:global_step/sec: 97.4725\n","INFO:tensorflow:loss = 0.054645516, step = 30601 (1.028 sec)\n","INFO:tensorflow:global_step/sec: 100.938\n","INFO:tensorflow:loss = 0.08584002, step = 30701 (0.992 sec)\n","INFO:tensorflow:global_step/sec: 95.7977\n","INFO:tensorflow:loss = 0.0620655, step = 30801 (1.041 sec)\n","INFO:tensorflow:global_step/sec: 99.6724\n","INFO:tensorflow:loss = 0.029489601, step = 30901 (1.006 sec)\n","INFO:tensorflow:global_step/sec: 94.2172\n","INFO:tensorflow:loss = 0.066843644, step = 31001 (1.060 sec)\n","INFO:tensorflow:global_step/sec: 98.0702\n","INFO:tensorflow:loss = 0.056237966, step = 31101 (1.020 sec)\n","INFO:tensorflow:global_step/sec: 100.412\n","INFO:tensorflow:loss = 0.0715107, step = 31201 (0.996 sec)\n","INFO:tensorflow:global_step/sec: 94.9884\n","INFO:tensorflow:loss = 0.053761385, step = 31301 (1.054 sec)\n","INFO:tensorflow:global_step/sec: 100.18\n","INFO:tensorflow:loss = 0.061292402, step = 31401 (0.997 sec)\n","INFO:tensorflow:global_step/sec: 94.7546\n","INFO:tensorflow:loss = 0.04926644, step = 31501 (1.056 sec)\n","INFO:tensorflow:global_step/sec: 98.695\n","INFO:tensorflow:loss = 0.057480913, step = 31601 (1.008 sec)\n","INFO:tensorflow:global_step/sec: 99.6324\n","INFO:tensorflow:loss = 0.06540423, step = 31701 (1.004 sec)\n","INFO:tensorflow:global_step/sec: 93.7889\n","INFO:tensorflow:loss = 0.04776561, step = 31801 (1.071 sec)\n","INFO:tensorflow:global_step/sec: 101.029\n","INFO:tensorflow:loss = 0.04491006, step = 31901 (0.984 sec)\n","INFO:tensorflow:global_step/sec: 94.5774\n","INFO:tensorflow:loss = 0.0299774, step = 32001 (1.062 sec)\n","INFO:tensorflow:global_step/sec: 99.0858\n","INFO:tensorflow:loss = 0.026811656, step = 32101 (1.005 sec)\n","INFO:tensorflow:global_step/sec: 98.9227\n","INFO:tensorflow:loss = 0.055219196, step = 32201 (1.011 sec)\n","INFO:tensorflow:global_step/sec: 95.4144\n","INFO:tensorflow:loss = 0.029235007, step = 32301 (1.053 sec)\n","INFO:tensorflow:global_step/sec: 102.274\n","INFO:tensorflow:loss = 0.055046294, step = 32401 (0.978 sec)\n","INFO:tensorflow:global_step/sec: 94.2139\n","INFO:tensorflow:loss = 0.039131742, step = 32501 (1.060 sec)\n","INFO:tensorflow:global_step/sec: 97.7208\n","INFO:tensorflow:loss = 0.038083717, step = 32601 (1.025 sec)\n","INFO:tensorflow:global_step/sec: 97.4453\n","INFO:tensorflow:loss = 0.057678793, step = 32701 (1.027 sec)\n","INFO:tensorflow:global_step/sec: 94.7425\n","INFO:tensorflow:loss = 0.040249962, step = 32801 (1.050 sec)\n","INFO:tensorflow:global_step/sec: 100.604\n","INFO:tensorflow:loss = 0.05038801, step = 32901 (0.998 sec)\n","INFO:tensorflow:global_step/sec: 93.0634\n","INFO:tensorflow:loss = 0.030030767, step = 33001 (1.075 sec)\n","INFO:tensorflow:global_step/sec: 98.8653\n","INFO:tensorflow:loss = 0.030974977, step = 33101 (1.012 sec)\n","INFO:tensorflow:global_step/sec: 98.2135\n","INFO:tensorflow:loss = 0.06552644, step = 33201 (1.018 sec)\n","INFO:tensorflow:global_step/sec: 96.2504\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.04991393, step = 33301 (1.037 sec)\n","INFO:tensorflow:global_step/sec: 101.512\n","INFO:tensorflow:loss = 0.039790466, step = 33401 (0.986 sec)\n","INFO:tensorflow:global_step/sec: 95.5779\n","INFO:tensorflow:loss = 0.052124687, step = 33501 (1.048 sec)\n","INFO:tensorflow:global_step/sec: 100.234\n","INFO:tensorflow:loss = 0.041813612, step = 33601 (0.997 sec)\n","INFO:tensorflow:global_step/sec: 99.2156\n","INFO:tensorflow:loss = 0.036760665, step = 33701 (1.007 sec)\n","INFO:tensorflow:global_step/sec: 95.2788\n","INFO:tensorflow:loss = 0.03418507, step = 33801 (1.049 sec)\n","INFO:tensorflow:global_step/sec: 99.9703\n","INFO:tensorflow:loss = 0.046955593, step = 33901 (1.009 sec)\n","INFO:tensorflow:global_step/sec: 93.2368\n","INFO:tensorflow:loss = 0.048118643, step = 34001 (1.065 sec)\n","INFO:tensorflow:global_step/sec: 100.661\n","INFO:tensorflow:loss = 0.061699595, step = 34101 (0.994 sec)\n","INFO:tensorflow:global_step/sec: 98.5398\n","INFO:tensorflow:loss = 0.051889192, step = 34201 (1.015 sec)\n","INFO:tensorflow:global_step/sec: 95.1464\n","INFO:tensorflow:loss = 0.06707879, step = 34301 (1.050 sec)\n","INFO:tensorflow:global_step/sec: 100.351\n","INFO:tensorflow:loss = 0.07537314, step = 34401 (0.996 sec)\n","INFO:tensorflow:global_step/sec: 92.9447\n","INFO:tensorflow:loss = 0.05287953, step = 34501 (1.077 sec)\n","INFO:tensorflow:global_step/sec: 99.1458\n","INFO:tensorflow:loss = 0.040913202, step = 34601 (1.007 sec)\n","INFO:tensorflow:global_step/sec: 97.6016\n","INFO:tensorflow:loss = 0.039254643, step = 34701 (1.025 sec)\n","INFO:tensorflow:global_step/sec: 95.0912\n","INFO:tensorflow:loss = 0.0557213, step = 34801 (1.053 sec)\n","INFO:tensorflow:global_step/sec: 99.8622\n","INFO:tensorflow:loss = 0.06667045, step = 34901 (1.002 sec)\n","INFO:tensorflow:global_step/sec: 93.3701\n","INFO:tensorflow:loss = 0.041869026, step = 35001 (1.071 sec)\n","INFO:tensorflow:global_step/sec: 100.864\n","INFO:tensorflow:loss = 0.051262375, step = 35101 (0.991 sec)\n","INFO:tensorflow:global_step/sec: 98.1998\n","INFO:tensorflow:loss = 0.039253805, step = 35201 (1.020 sec)\n","INFO:tensorflow:global_step/sec: 95.3195\n","INFO:tensorflow:loss = 0.046469755, step = 35301 (1.048 sec)\n","INFO:tensorflow:global_step/sec: 98.0127\n","INFO:tensorflow:loss = 0.040403154, step = 35401 (1.019 sec)\n","INFO:tensorflow:global_step/sec: 93.3411\n","INFO:tensorflow:loss = 0.040038846, step = 35501 (1.073 sec)\n","INFO:tensorflow:global_step/sec: 99.9289\n","INFO:tensorflow:loss = 0.03742171, step = 35601 (1.002 sec)\n","INFO:tensorflow:global_step/sec: 99.2367\n","INFO:tensorflow:loss = 0.049389906, step = 35701 (1.007 sec)\n","INFO:tensorflow:global_step/sec: 94.0408\n","INFO:tensorflow:loss = 0.04096717, step = 35801 (1.060 sec)\n","INFO:tensorflow:global_step/sec: 99.4754\n","INFO:tensorflow:loss = 0.05895488, step = 35901 (1.007 sec)\n","INFO:tensorflow:global_step/sec: 95.3252\n","INFO:tensorflow:loss = 0.021143787, step = 36001 (1.049 sec)\n","INFO:tensorflow:global_step/sec: 100.61\n","INFO:tensorflow:loss = 0.03707479, step = 36101 (0.994 sec)\n","INFO:tensorflow:global_step/sec: 99.4186\n","INFO:tensorflow:loss = 0.043686617, step = 36201 (1.014 sec)\n","INFO:tensorflow:global_step/sec: 95.2864\n","INFO:tensorflow:loss = 0.06743321, step = 36301 (1.041 sec)\n","INFO:tensorflow:global_step/sec: 100.004\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.07621821, step = 36401 (1.000 sec)\n","INFO:tensorflow:global_step/sec: 94.2352\n","INFO:tensorflow:loss = 0.057586245, step = 36501 (1.061 sec)\n","INFO:tensorflow:global_step/sec: 99.6285\n","INFO:tensorflow:loss = 0.039539207, step = 36601 (1.004 sec)\n","INFO:tensorflow:global_step/sec: 99.7903\n","INFO:tensorflow:loss = 0.050203506, step = 36701 (1.002 sec)\n","INFO:tensorflow:global_step/sec: 92.7856\n","INFO:tensorflow:loss = 0.045206547, step = 36801 (1.080 sec)\n","INFO:tensorflow:global_step/sec: 100.293\n","INFO:tensorflow:loss = 0.06018275, step = 36901 (0.991 sec)\n","INFO:tensorflow:global_step/sec: 95.0199\n","INFO:tensorflow:loss = 0.0402413, step = 37001 (1.056 sec)\n","INFO:tensorflow:global_step/sec: 101.418\n","INFO:tensorflow:loss = 0.043738816, step = 37101 (0.988 sec)\n","INFO:tensorflow:global_step/sec: 99.7579\n","INFO:tensorflow:loss = 0.030885488, step = 37201 (0.997 sec)\n","INFO:tensorflow:global_step/sec: 94.1272\n","INFO:tensorflow:loss = 0.03215975, step = 37301 (1.068 sec)\n","INFO:tensorflow:global_step/sec: 98.7795\n","INFO:tensorflow:loss = 0.03468954, step = 37401 (1.012 sec)\n","INFO:tensorflow:global_step/sec: 95.0954\n","INFO:tensorflow:loss = 0.015332305, step = 37501 (1.047 sec)\n","INFO:tensorflow:global_step/sec: 100.46\n","INFO:tensorflow:loss = 0.061702278, step = 37601 (0.998 sec)\n","INFO:tensorflow:global_step/sec: 99.7045\n","INFO:tensorflow:loss = 0.04656787, step = 37701 (1.001 sec)\n","INFO:tensorflow:global_step/sec: 93.4452\n","INFO:tensorflow:loss = 0.034549188, step = 37801 (1.074 sec)\n","INFO:tensorflow:global_step/sec: 98.5658\n","INFO:tensorflow:loss = 0.040547334, step = 37901 (1.010 sec)\n","INFO:tensorflow:global_step/sec: 94.1993\n","INFO:tensorflow:loss = 0.03353708, step = 38001 (1.066 sec)\n","INFO:tensorflow:global_step/sec: 100.177\n","INFO:tensorflow:loss = 0.050468616, step = 38101 (0.997 sec)\n","INFO:tensorflow:global_step/sec: 99.828\n","INFO:tensorflow:loss = 0.046796855, step = 38201 (1.002 sec)\n","INFO:tensorflow:global_step/sec: 94.5484\n","INFO:tensorflow:loss = 0.044151384, step = 38301 (1.058 sec)\n","INFO:tensorflow:global_step/sec: 99.6767\n","INFO:tensorflow:loss = 0.041974343, step = 38401 (1.005 sec)\n","INFO:tensorflow:global_step/sec: 93.9856\n","INFO:tensorflow:loss = 0.022548918, step = 38501 (1.064 sec)\n","INFO:tensorflow:global_step/sec: 101.076\n","INFO:tensorflow:loss = 0.04180551, step = 38601 (0.987 sec)\n","INFO:tensorflow:global_step/sec: 101.422\n","INFO:tensorflow:loss = 0.045447793, step = 38701 (0.988 sec)\n","INFO:tensorflow:global_step/sec: 92.4543\n","INFO:tensorflow:loss = 0.05085764, step = 38801 (1.081 sec)\n","INFO:tensorflow:global_step/sec: 99.4967\n","INFO:tensorflow:loss = 0.039743245, step = 38901 (1.006 sec)\n","INFO:tensorflow:global_step/sec: 93.9194\n","INFO:tensorflow:loss = 0.041724462, step = 39001 (1.065 sec)\n","INFO:tensorflow:global_step/sec: 99.3519\n","INFO:tensorflow:loss = 0.0335421, step = 39101 (1.004 sec)\n","INFO:tensorflow:global_step/sec: 100.493\n","INFO:tensorflow:loss = 0.037723247, step = 39201 (0.996 sec)\n","INFO:tensorflow:global_step/sec: 94.4625\n","INFO:tensorflow:loss = 0.05142941, step = 39301 (1.059 sec)\n","INFO:tensorflow:global_step/sec: 100.12\n","INFO:tensorflow:loss = 0.04622713, step = 39401 (0.996 sec)\n","INFO:tensorflow:global_step/sec: 95.011\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.025799021, step = 39501 (1.057 sec)\n","INFO:tensorflow:global_step/sec: 99.0096\n","INFO:tensorflow:loss = 0.056290396, step = 39601 (1.004 sec)\n","INFO:tensorflow:global_step/sec: 99.9974\n","INFO:tensorflow:loss = 0.05371637, step = 39701 (1.004 sec)\n","INFO:tensorflow:global_step/sec: 93.0135\n","INFO:tensorflow:loss = 0.035072632, step = 39801 (1.075 sec)\n","INFO:tensorflow:global_step/sec: 100.797\n","INFO:tensorflow:loss = 0.029252332, step = 39901 (0.989 sec)\n","INFO:tensorflow:global_step/sec: 95.4597\n","INFO:tensorflow:loss = 0.031878807, step = 40001 (1.052 sec)\n","INFO:tensorflow:global_step/sec: 99.8659\n","INFO:tensorflow:loss = 0.045441344, step = 40101 (1.003 sec)\n","INFO:tensorflow:global_step/sec: 101.689\n","INFO:tensorflow:loss = 0.026312578, step = 40201 (0.979 sec)\n","INFO:tensorflow:global_step/sec: 94.6024\n","INFO:tensorflow:loss = 0.0328867, step = 40301 (1.057 sec)\n","INFO:tensorflow:global_step/sec: 99.5765\n","INFO:tensorflow:loss = 0.030684112, step = 40401 (1.005 sec)\n","INFO:tensorflow:global_step/sec: 92.9631\n","INFO:tensorflow:loss = 0.025911976, step = 40501 (1.079 sec)\n","INFO:tensorflow:global_step/sec: 98.5131\n","INFO:tensorflow:loss = 0.026747249, step = 40601 (1.010 sec)\n","INFO:tensorflow:global_step/sec: 99.6161\n","INFO:tensorflow:loss = 0.024302466, step = 40701 (1.003 sec)\n","INFO:tensorflow:global_step/sec: 94.6598\n","INFO:tensorflow:loss = 0.036172934, step = 40801 (1.058 sec)\n","INFO:tensorflow:global_step/sec: 98.0664\n","INFO:tensorflow:loss = 0.021120079, step = 40901 (1.021 sec)\n","INFO:tensorflow:global_step/sec: 95.5371\n","INFO:tensorflow:loss = 0.024278488, step = 41001 (1.047 sec)\n","INFO:tensorflow:global_step/sec: 98.6459\n","INFO:tensorflow:loss = 0.036249936, step = 41101 (1.014 sec)\n","INFO:tensorflow:global_step/sec: 99.294\n","INFO:tensorflow:loss = 0.043750618, step = 41201 (1.007 sec)\n","INFO:tensorflow:global_step/sec: 95.1962\n","INFO:tensorflow:loss = 0.033796206, step = 41301 (1.048 sec)\n","INFO:tensorflow:global_step/sec: 98.0007\n","INFO:tensorflow:loss = 0.03244545, step = 41401 (1.024 sec)\n","INFO:tensorflow:global_step/sec: 95.1411\n","INFO:tensorflow:loss = 0.040960915, step = 41501 (1.049 sec)\n","INFO:tensorflow:global_step/sec: 100.053\n","INFO:tensorflow:loss = 0.028822694, step = 41601 (0.999 sec)\n","INFO:tensorflow:global_step/sec: 100.562\n","INFO:tensorflow:loss = 0.030524502, step = 41701 (0.994 sec)\n","INFO:tensorflow:global_step/sec: 94.3972\n","INFO:tensorflow:loss = 0.06258574, step = 41801 (1.061 sec)\n","INFO:tensorflow:global_step/sec: 97.571\n","INFO:tensorflow:loss = 0.033423543, step = 41901 (1.025 sec)\n","INFO:tensorflow:global_step/sec: 93.6318\n","INFO:tensorflow:loss = 0.041745506, step = 42001 (1.066 sec)\n","INFO:tensorflow:global_step/sec: 99.2567\n","INFO:tensorflow:loss = 0.038245715, step = 42101 (1.006 sec)\n","INFO:tensorflow:global_step/sec: 98.5642\n","INFO:tensorflow:loss = 0.028313022, step = 42201 (1.015 sec)\n","INFO:tensorflow:global_step/sec: 95.2363\n","INFO:tensorflow:loss = 0.034720056, step = 42301 (1.050 sec)\n","INFO:tensorflow:global_step/sec: 98.2691\n","INFO:tensorflow:loss = 0.02949413, step = 42401 (1.020 sec)\n","INFO:tensorflow:global_step/sec: 94.65\n","INFO:tensorflow:loss = 0.02530036, step = 42501 (1.056 sec)\n","INFO:tensorflow:global_step/sec: 99.8099\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.037339523, step = 42601 (1.003 sec)\n","INFO:tensorflow:global_step/sec: 99.2127\n","INFO:tensorflow:loss = 0.044002313, step = 42701 (1.003 sec)\n","INFO:tensorflow:global_step/sec: 94.9194\n","INFO:tensorflow:loss = 0.034873765, step = 42801 (1.057 sec)\n","INFO:tensorflow:global_step/sec: 97.3845\n","INFO:tensorflow:loss = 0.025328917, step = 42901 (1.028 sec)\n","INFO:tensorflow:global_step/sec: 93.6151\n","INFO:tensorflow:loss = 0.026125748, step = 43001 (1.070 sec)\n","INFO:tensorflow:global_step/sec: 97.9726\n","INFO:tensorflow:loss = 0.039671328, step = 43101 (1.019 sec)\n","INFO:tensorflow:global_step/sec: 98.5708\n","INFO:tensorflow:loss = 0.035398558, step = 43201 (1.013 sec)\n","INFO:tensorflow:global_step/sec: 94.9185\n","INFO:tensorflow:loss = 0.023641437, step = 43301 (1.055 sec)\n","INFO:tensorflow:global_step/sec: 98.6153\n","INFO:tensorflow:loss = 0.038740825, step = 43401 (1.011 sec)\n","INFO:tensorflow:global_step/sec: 93.5678\n","INFO:tensorflow:loss = 0.022191186, step = 43501 (1.068 sec)\n","INFO:tensorflow:global_step/sec: 101.678\n","INFO:tensorflow:loss = 0.013247013, step = 43601 (0.986 sec)\n","INFO:tensorflow:global_step/sec: 98.9988\n","INFO:tensorflow:loss = 0.021267796, step = 43701 (1.011 sec)\n","INFO:tensorflow:global_step/sec: 95.0494\n","INFO:tensorflow:loss = 0.034598425, step = 43801 (1.052 sec)\n","INFO:tensorflow:global_step/sec: 99.2266\n","INFO:tensorflow:loss = 0.020936409, step = 43901 (1.008 sec)\n","INFO:tensorflow:global_step/sec: 94.4826\n","INFO:tensorflow:loss = 0.024339607, step = 44001 (1.058 sec)\n","INFO:tensorflow:global_step/sec: 100.626\n","INFO:tensorflow:loss = 0.020655436, step = 44101 (0.993 sec)\n","INFO:tensorflow:global_step/sec: 100.215\n","INFO:tensorflow:loss = 0.037342973, step = 44201 (0.995 sec)\n","INFO:tensorflow:global_step/sec: 91.0492\n","INFO:tensorflow:loss = 0.023389101, step = 44301 (1.098 sec)\n","INFO:tensorflow:global_step/sec: 97.4848\n","INFO:tensorflow:loss = 0.022939382, step = 44401 (1.031 sec)\n","INFO:tensorflow:global_step/sec: 95.0473\n","INFO:tensorflow:loss = 0.031983186, step = 44501 (1.049 sec)\n","INFO:tensorflow:global_step/sec: 99.4162\n","INFO:tensorflow:loss = 0.029267924, step = 44601 (1.007 sec)\n","INFO:tensorflow:global_step/sec: 100.106\n","INFO:tensorflow:loss = 0.032656427, step = 44701 (1.000 sec)\n","INFO:tensorflow:global_step/sec: 94.6989\n","INFO:tensorflow:loss = 0.033772923, step = 44801 (1.057 sec)\n","INFO:tensorflow:global_step/sec: 100.015\n","INFO:tensorflow:loss = 0.033084396, step = 44901 (1.000 sec)\n","INFO:tensorflow:global_step/sec: 95.3365\n","INFO:tensorflow:loss = 0.0415248, step = 45001 (1.048 sec)\n","INFO:tensorflow:global_step/sec: 100.806\n","INFO:tensorflow:loss = 0.03977162, step = 45101 (0.994 sec)\n","INFO:tensorflow:global_step/sec: 99.3292\n","INFO:tensorflow:loss = 0.026718207, step = 45201 (1.006 sec)\n","INFO:tensorflow:global_step/sec: 95.3122\n","INFO:tensorflow:loss = 0.03422638, step = 45301 (1.048 sec)\n","INFO:tensorflow:global_step/sec: 99.0047\n","INFO:tensorflow:loss = 0.030719653, step = 45401 (1.013 sec)\n","INFO:tensorflow:global_step/sec: 91.1888\n","INFO:tensorflow:loss = 0.018382475, step = 45501 (1.096 sec)\n","INFO:tensorflow:global_step/sec: 99.6871\n","INFO:tensorflow:loss = 0.025273083, step = 45601 (1.009 sec)\n","INFO:tensorflow:global_step/sec: 98.5186\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.03548154, step = 45701 (1.008 sec)\n","INFO:tensorflow:global_step/sec: 95.7904\n","INFO:tensorflow:loss = 0.047826275, step = 45801 (1.044 sec)\n","INFO:tensorflow:global_step/sec: 98.8466\n","INFO:tensorflow:loss = 0.040291924, step = 45901 (1.012 sec)\n","INFO:tensorflow:global_step/sec: 93.3045\n","INFO:tensorflow:loss = 0.022673763, step = 46001 (1.072 sec)\n","INFO:tensorflow:global_step/sec: 100.95\n","INFO:tensorflow:loss = 0.05041736, step = 46101 (0.990 sec)\n","INFO:tensorflow:global_step/sec: 99.2801\n","INFO:tensorflow:loss = 0.033098143, step = 46201 (1.007 sec)\n","INFO:tensorflow:global_step/sec: 96.1888\n","INFO:tensorflow:loss = 0.022827202, step = 46301 (1.042 sec)\n","INFO:tensorflow:global_step/sec: 99.7233\n","INFO:tensorflow:loss = 0.01079429, step = 46401 (1.001 sec)\n","INFO:tensorflow:global_step/sec: 92.3168\n","INFO:tensorflow:loss = 0.03702905, step = 46501 (1.083 sec)\n","INFO:tensorflow:global_step/sec: 101.053\n","INFO:tensorflow:loss = 0.015336064, step = 46601 (0.988 sec)\n","INFO:tensorflow:global_step/sec: 97.5071\n","INFO:tensorflow:loss = 0.04543066, step = 46701 (1.028 sec)\n","INFO:tensorflow:global_step/sec: 93.6358\n","INFO:tensorflow:loss = 0.030413548, step = 46801 (1.068 sec)\n","INFO:tensorflow:global_step/sec: 99.5236\n","INFO:tensorflow:loss = 0.021294013, step = 46901 (1.005 sec)\n","INFO:tensorflow:global_step/sec: 92.9807\n","INFO:tensorflow:loss = 0.02734554, step = 47001 (1.071 sec)\n","INFO:tensorflow:global_step/sec: 101.602\n","INFO:tensorflow:loss = 0.030541744, step = 47101 (0.988 sec)\n","INFO:tensorflow:global_step/sec: 99.2508\n","INFO:tensorflow:loss = 0.03226351, step = 47201 (1.007 sec)\n","INFO:tensorflow:global_step/sec: 94.2708\n","INFO:tensorflow:loss = 0.022817133, step = 47301 (1.059 sec)\n","INFO:tensorflow:global_step/sec: 99.2494\n","INFO:tensorflow:loss = 0.038345, step = 47401 (1.011 sec)\n","INFO:tensorflow:global_step/sec: 92.8479\n","INFO:tensorflow:loss = 0.038691264, step = 47501 (1.075 sec)\n","INFO:tensorflow:global_step/sec: 100.895\n","INFO:tensorflow:loss = 0.022683645, step = 47601 (0.988 sec)\n","INFO:tensorflow:global_step/sec: 99.7137\n","INFO:tensorflow:loss = 0.03219535, step = 47701 (1.007 sec)\n","INFO:tensorflow:global_step/sec: 94.868\n","INFO:tensorflow:loss = 0.03228379, step = 47801 (1.055 sec)\n","INFO:tensorflow:global_step/sec: 99.322\n","INFO:tensorflow:loss = 0.026766727, step = 47901 (1.005 sec)\n","INFO:tensorflow:global_step/sec: 92.2169\n","INFO:tensorflow:loss = 0.03537189, step = 48001 (1.084 sec)\n","INFO:tensorflow:global_step/sec: 98.2632\n","INFO:tensorflow:loss = 0.018651431, step = 48101 (1.018 sec)\n","INFO:tensorflow:global_step/sec: 100.659\n","INFO:tensorflow:loss = 0.03131104, step = 48201 (0.990 sec)\n","INFO:tensorflow:global_step/sec: 93.5624\n","INFO:tensorflow:loss = 0.017706044, step = 48301 (1.072 sec)\n","INFO:tensorflow:global_step/sec: 100.092\n","INFO:tensorflow:loss = 0.034112025, step = 48401 (0.996 sec)\n","INFO:tensorflow:global_step/sec: 93.3714\n","INFO:tensorflow:loss = 0.031792812, step = 48501 (1.075 sec)\n","INFO:tensorflow:global_step/sec: 99.4639\n","INFO:tensorflow:loss = 0.02346484, step = 48601 (1.006 sec)\n","INFO:tensorflow:global_step/sec: 100.104\n","INFO:tensorflow:loss = 0.036921468, step = 48701 (0.999 sec)\n","INFO:tensorflow:global_step/sec: 93.109\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.03677236, step = 48801 (1.072 sec)\n","INFO:tensorflow:global_step/sec: 98.3783\n","INFO:tensorflow:loss = 0.046143167, step = 48901 (1.018 sec)\n","INFO:tensorflow:global_step/sec: 92.8336\n","INFO:tensorflow:loss = 0.036993146, step = 49001 (1.080 sec)\n","INFO:tensorflow:global_step/sec: 100.582\n","INFO:tensorflow:loss = 0.033099025, step = 49101 (0.994 sec)\n","INFO:tensorflow:global_step/sec: 100.966\n","INFO:tensorflow:loss = 0.025964916, step = 49201 (0.988 sec)\n","INFO:tensorflow:global_step/sec: 93.3765\n","INFO:tensorflow:loss = 0.03626041, step = 49301 (1.070 sec)\n","INFO:tensorflow:global_step/sec: 101.554\n","INFO:tensorflow:loss = 0.03224695, step = 49401 (0.986 sec)\n","INFO:tensorflow:global_step/sec: 94.9531\n","INFO:tensorflow:loss = 0.026801202, step = 49501 (1.053 sec)\n","INFO:tensorflow:global_step/sec: 99.1612\n","INFO:tensorflow:loss = 0.019797357, step = 49601 (1.008 sec)\n","INFO:tensorflow:global_step/sec: 101.157\n","INFO:tensorflow:loss = 0.014868869, step = 49701 (0.984 sec)\n","INFO:tensorflow:global_step/sec: 96.1514\n","INFO:tensorflow:loss = 0.029260924, step = 49801 (1.045 sec)\n","INFO:tensorflow:global_step/sec: 98.7853\n","INFO:tensorflow:loss = 0.020343784, step = 49901 (1.013 sec)\n","INFO:tensorflow:Saving checkpoints for 50000 into /tmp/tmppw5q4h5g/bow_embeddings/model.ckpt.\n","INFO:tensorflow:Loss for final step: 0.022213522.\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2018-03-06-16:58:10\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmppw5q4h5g/bow_embeddings/model.ckpt-50000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Finished evaluation at 2018-03-06-16:58:13\n","INFO:tensorflow:Saving dict for global step 50000: accuracy = 0.83512, accuracy_baseline = 0.5, auc = 0.8628526, auc_precision_recall = 0.88969934, average_loss = 2.328712, global_step = 50000, label/mean = 0.5, loss = 232.87119, prediction/mean = 0.4890257\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmppw5q4h5g/bow_embeddings/model.ckpt-50000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"}]},{"metadata":{"id":"p9q7qfXrvq-J","colab_type":"text"},"cell_type":"markdown","source":["We can use TensorBoard to visualize our $50$-dimensional word vectors projected into $\\mathbb{R}^3$ using [t-SNE](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding). We expect similar word to be close to each other. This can be a useful way to inspect our model weights and find unexpected behaviours. There's plenty of more information to go deeper [here](https://www.tensorflow.org/programmers_guide/embedding). The following snippet will generate a vocabulary file `metadata.tsv` that lists all the tokens in order. In the **PROJECTOR** tab in *TensorBoard* you can load it to visualize your vectors and there's also the [standalone projector visualizer](http://projector.tensorflow.org) that can be used to check out different embeddings.\n","\n","![Embedding image](https://github.com/eisenjulian/nlp_estimator_tutorial/blob/master/embeddings.gif?raw=true)"]},{"metadata":{"id":"ujVD4Yv0vq-J","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["with open(os.path.join(model_dir, 'metadata.tsv'), 'w', encoding=\"utf-8\") as f:\n","    f.write('label\\n')\n","    for index in range(0, vocab_size):\n","        f.write(word_inverted_index[index] + '\\n')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"K9SKqlRpvq-N","colab_type":"text"},"cell_type":"markdown","source":["### Convolutions\n","\n","At this point one possible approach would be to go deeper, further adding more fully connected layers and playing around with layer sizes and training functions. However, by doing that we would add extra complexity and ignore important structure in our sentences. Words do not live in a vacuum and meaning is compositional, formed by words and its neighbors.\n","\n","Convolutions are one way to take advantage of this structure, similar to how we can model salient clusters of pixels for [image classification](https://www.tensorflow.org/tutorials/layers). The intuition is that certain sequences of words, or *n-grams*, usually have the same meaning regardless of their overall position in the sentence. Introducing a structural prior via the convolution operation allows us to model the interaction between neighboring words and consequently gives us a better way to represent such meaning."]},{"metadata":{"id":"mdIuS0-65eNB","colab_type":"text"},"cell_type":"markdown","source":["### Creating a custom estimator\n","\n","The `tf.estimator` framework provides a higher level API for training machine learning models, defining `train()`, `evaluate()` and `predict()` operations, handling checkpointing, loading, initializing, serving, building the graph and the session out of the box. One the many benefits it provides is that the same code will be able to run in CPUs, GPUs and even in a distributed setup. There's a small family of pre-made estimators, like the ones we used earlier, but it's most likely that you will need to build your own. [This](https://www.tensorflow.org/extend/estimators) guide contains a thorough explanation on how to do it.\n","\n","We will use a `Head` to simplify the writing of our model function `model_fn`. The head already knows how to compute predictions, loss, train_op, metrics and export outputs, and can be reused across models. We will use `binary_classification_head`, which is a head for single label binary classification that uses `sigmoid_cross_entropy_with_logits` loss.\n","\n","The model presented here is a port from [this example](https://github.com/keras-team/keras/blob/master/examples/imdb_cnn.py) into the `Estimator` API."]},{"metadata":{"id":"Wf-sGICDejgx","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":71},"outputId":"3013573a-b39f-426b-80d3-0630b7107149","executionInfo":{"status":"ok","timestamp":1520355499529,"user_tz":0,"elapsed":1314,"user":{"displayName":"Sebastian Ruder","photoUrl":"//lh5.googleusercontent.com/-_RsKB476gus/AAAAAAAAAAI/AAAAAAAAVys/bDJNFfUAEUU/s50-c-k-no/photo.jpg","userId":"101962136952284559776"}}},"cell_type":"code","source":["head = tf.contrib.estimator.binary_classification_head()\n","\n","def cnn_model_fn(features, labels, mode, params):    \n","    input_layer = tf.contrib.layers.embed_sequence(\n","        features['x'], vocab_size, embedding_size,\n","        initializer=params['embedding_initializer'])\n","    \n","    training = mode == tf.estimator.ModeKeys.TRAIN\n","    dropout_emb = tf.layers.dropout(inputs=input_layer, \n","                                    rate=0.2, \n","                                    training=training)\n","\n","    conv = tf.layers.conv1d(\n","        inputs=dropout_emb,\n","        filters=32,\n","        kernel_size=3,\n","        padding=\"same\",\n","        activation=tf.nn.relu)\n","    \n","    # Global Max Pooling\n","    pool = tf.reduce_max(input_tensor=conv, axis=1)\n","    \n","    hidden = tf.layers.dense(inputs=pool, units=250, activation=tf.nn.relu)\n","    \n","    dropout_hidden = tf.layers.dropout(inputs=hidden, \n","                                       rate=0.2, \n","                                       training=training)\n","    \n","    logits = tf.layers.dense(inputs=dropout_hidden, units=1)\n","    \n","    # This will be None when predicting\n","    if labels is not None:\n","        labels = tf.reshape(labels, [-1, 1])\n","        \n","\n","    optimizer = tf.train.AdamOptimizer()\n","    \n","    def _train_op_fn(loss):\n","        return optimizer.minimize(\n","            loss=loss,\n","            global_step=tf.train.get_global_step())\n","\n","    return head.create_estimator_spec(\n","        features=features,\n","        labels=labels,\n","        mode=mode,\n","        logits=logits, \n","        train_op_fn=_train_op_fn)\n","  \n","params = {'embedding_initializer': tf.random_uniform_initializer(-1.0, 1.0)}\n","cnn_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn,\n","                                        model_dir=os.path.join(model_dir, 'cnn'),\n","                                        params=params)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using default config.\n","INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmppw5q4h5g/cnn', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff80d143470>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stdout"}]},{"metadata":{"id":"_ndMYmQ5qNk2","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":8979},"outputId":"8a8ec2d2-d467-4e0d-a964-3eaba1258f50","executionInfo":{"status":"ok","timestamp":1520355697562,"user_tz":0,"elapsed":197228,"user":{"displayName":"Sebastian Ruder","photoUrl":"//lh5.googleusercontent.com/-_RsKB476gus/AAAAAAAAAAI/AAAAAAAAVys/bDJNFfUAEUU/s50-c-k-no/photo.jpg","userId":"101962136952284559776"}}},"cell_type":"code","source":["train_and_evaluate(cnn_classifier)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`NHWC` for data_format is deprecated, use `NWC` instead\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmppw5q4h5g/cnn/model.ckpt.\n","INFO:tensorflow:loss = 71.00276, step = 1\n","INFO:tensorflow:global_step/sec: 131.247\n","INFO:tensorflow:loss = 70.4605, step = 101 (0.763 sec)\n","INFO:tensorflow:global_step/sec: 142.61\n","INFO:tensorflow:loss = 60.6081, step = 201 (0.703 sec)\n","INFO:tensorflow:global_step/sec: 139.916\n","INFO:tensorflow:loss = 51.375065, step = 301 (0.716 sec)\n","INFO:tensorflow:global_step/sec: 144.106\n","INFO:tensorflow:loss = 54.94073, step = 401 (0.696 sec)\n","INFO:tensorflow:global_step/sec: 137.382\n","INFO:tensorflow:loss = 36.194225, step = 501 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 142.764\n","INFO:tensorflow:loss = 32.856915, step = 601 (0.700 sec)\n","INFO:tensorflow:global_step/sec: 144.271\n","INFO:tensorflow:loss = 43.513416, step = 701 (0.689 sec)\n","INFO:tensorflow:global_step/sec: 132.046\n","INFO:tensorflow:loss = 27.204342, step = 801 (0.760 sec)\n","INFO:tensorflow:global_step/sec: 146.022\n","INFO:tensorflow:loss = 38.514263, step = 901 (0.684 sec)\n","INFO:tensorflow:global_step/sec: 135.309\n","INFO:tensorflow:loss = 28.41256, step = 1001 (0.741 sec)\n","INFO:tensorflow:global_step/sec: 149.718\n","INFO:tensorflow:loss = 39.17546, step = 1101 (0.668 sec)\n","INFO:tensorflow:global_step/sec: 145.188\n","INFO:tensorflow:loss = 33.415226, step = 1201 (0.687 sec)\n","INFO:tensorflow:global_step/sec: 131.703\n","INFO:tensorflow:loss = 25.662094, step = 1301 (0.762 sec)\n","INFO:tensorflow:global_step/sec: 143.615\n","INFO:tensorflow:loss = 27.064392, step = 1401 (0.693 sec)\n","INFO:tensorflow:global_step/sec: 134.339\n","INFO:tensorflow:loss = 25.931738, step = 1501 (0.745 sec)\n","INFO:tensorflow:global_step/sec: 140.824\n","INFO:tensorflow:loss = 30.387602, step = 1601 (0.711 sec)\n","INFO:tensorflow:global_step/sec: 143.308\n","INFO:tensorflow:loss = 32.213165, step = 1701 (0.698 sec)\n","INFO:tensorflow:global_step/sec: 132.958\n","INFO:tensorflow:loss = 31.761671, step = 1801 (0.756 sec)\n","INFO:tensorflow:global_step/sec: 141.513\n","INFO:tensorflow:loss = 22.596552, step = 1901 (0.701 sec)\n","INFO:tensorflow:global_step/sec: 129.272\n","INFO:tensorflow:loss = 29.474604, step = 2001 (0.777 sec)\n","INFO:tensorflow:global_step/sec: 142.897\n","INFO:tensorflow:loss = 25.87828, step = 2101 (0.698 sec)\n","INFO:tensorflow:global_step/sec: 143.551\n","INFO:tensorflow:loss = 40.544098, step = 2201 (0.698 sec)\n","INFO:tensorflow:global_step/sec: 131.655\n","INFO:tensorflow:loss = 27.168419, step = 2301 (0.755 sec)\n","INFO:tensorflow:global_step/sec: 139.931\n","INFO:tensorflow:loss = 23.001999, step = 2401 (0.714 sec)\n","INFO:tensorflow:global_step/sec: 132.425\n","INFO:tensorflow:loss = 28.866613, step = 2501 (0.764 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 142.515\n","INFO:tensorflow:loss = 22.105951, step = 2601 (0.693 sec)\n","INFO:tensorflow:global_step/sec: 142.432\n","INFO:tensorflow:loss = 26.981665, step = 2701 (0.706 sec)\n","INFO:tensorflow:global_step/sec: 128.306\n","INFO:tensorflow:loss = 15.109493, step = 2801 (0.777 sec)\n","INFO:tensorflow:global_step/sec: 143.983\n","INFO:tensorflow:loss = 19.818504, step = 2901 (0.695 sec)\n","INFO:tensorflow:global_step/sec: 135.463\n","INFO:tensorflow:loss = 16.703423, step = 3001 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 144.705\n","INFO:tensorflow:loss = 11.5601225, step = 3101 (0.697 sec)\n","INFO:tensorflow:global_step/sec: 138.846\n","INFO:tensorflow:loss = 16.464888, step = 3201 (0.717 sec)\n","INFO:tensorflow:global_step/sec: 132.074\n","INFO:tensorflow:loss = 9.508666, step = 3301 (0.756 sec)\n","INFO:tensorflow:global_step/sec: 143.006\n","INFO:tensorflow:loss = 29.020666, step = 3401 (0.699 sec)\n","INFO:tensorflow:global_step/sec: 130.12\n","INFO:tensorflow:loss = 13.530551, step = 3501 (0.767 sec)\n","INFO:tensorflow:global_step/sec: 141.444\n","INFO:tensorflow:loss = 26.911491, step = 3601 (0.708 sec)\n","INFO:tensorflow:global_step/sec: 144.603\n","INFO:tensorflow:loss = 17.579136, step = 3701 (0.692 sec)\n","INFO:tensorflow:global_step/sec: 131.284\n","INFO:tensorflow:loss = 24.585838, step = 3801 (0.759 sec)\n","INFO:tensorflow:global_step/sec: 142.15\n","INFO:tensorflow:loss = 17.396114, step = 3901 (0.702 sec)\n","INFO:tensorflow:global_step/sec: 131.507\n","INFO:tensorflow:loss = 16.35411, step = 4001 (0.761 sec)\n","INFO:tensorflow:global_step/sec: 142.523\n","INFO:tensorflow:loss = 23.401072, step = 4101 (0.705 sec)\n","INFO:tensorflow:global_step/sec: 140.301\n","INFO:tensorflow:loss = 26.473318, step = 4201 (0.713 sec)\n","INFO:tensorflow:global_step/sec: 131.328\n","INFO:tensorflow:loss = 11.892812, step = 4301 (0.762 sec)\n","INFO:tensorflow:global_step/sec: 144.527\n","INFO:tensorflow:loss = 12.860988, step = 4401 (0.692 sec)\n","INFO:tensorflow:global_step/sec: 130.873\n","INFO:tensorflow:loss = 13.361986, step = 4501 (0.764 sec)\n","INFO:tensorflow:global_step/sec: 141.759\n","INFO:tensorflow:loss = 8.379169, step = 4601 (0.707 sec)\n","INFO:tensorflow:global_step/sec: 143.104\n","INFO:tensorflow:loss = 11.075922, step = 4701 (0.698 sec)\n","INFO:tensorflow:global_step/sec: 130.054\n","INFO:tensorflow:loss = 19.123833, step = 4801 (0.766 sec)\n","INFO:tensorflow:global_step/sec: 139.941\n","INFO:tensorflow:loss = 9.280981, step = 4901 (0.715 sec)\n","INFO:tensorflow:global_step/sec: 133.87\n","INFO:tensorflow:loss = 14.94582, step = 5001 (0.748 sec)\n","INFO:tensorflow:global_step/sec: 139.687\n","INFO:tensorflow:loss = 8.241052, step = 5101 (0.716 sec)\n","INFO:tensorflow:global_step/sec: 140.837\n","INFO:tensorflow:loss = 8.4230795, step = 5201 (0.706 sec)\n","INFO:tensorflow:global_step/sec: 130.674\n","INFO:tensorflow:loss = 11.453256, step = 5301 (0.770 sec)\n","INFO:tensorflow:global_step/sec: 139.622\n","INFO:tensorflow:loss = 11.426154, step = 5401 (0.713 sec)\n","INFO:tensorflow:global_step/sec: 131.087\n","INFO:tensorflow:loss = 9.519495, step = 5501 (0.766 sec)\n","INFO:tensorflow:global_step/sec: 141.578\n","INFO:tensorflow:loss = 17.970573, step = 5601 (0.706 sec)\n","INFO:tensorflow:global_step/sec: 140.537\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 14.459528, step = 5701 (0.711 sec)\n","INFO:tensorflow:global_step/sec: 131.582\n","INFO:tensorflow:loss = 10.683574, step = 5801 (0.761 sec)\n","INFO:tensorflow:global_step/sec: 141.846\n","INFO:tensorflow:loss = 13.597704, step = 5901 (0.702 sec)\n","INFO:tensorflow:global_step/sec: 133.455\n","INFO:tensorflow:loss = 8.665482, step = 6001 (0.751 sec)\n","INFO:tensorflow:global_step/sec: 142.382\n","INFO:tensorflow:loss = 12.834925, step = 6101 (0.704 sec)\n","INFO:tensorflow:global_step/sec: 144.705\n","INFO:tensorflow:loss = 5.7017503, step = 6201 (0.689 sec)\n","INFO:tensorflow:global_step/sec: 129.761\n","INFO:tensorflow:loss = 13.748979, step = 6301 (0.772 sec)\n","INFO:tensorflow:global_step/sec: 141.517\n","INFO:tensorflow:loss = 8.34773, step = 6401 (0.705 sec)\n","INFO:tensorflow:global_step/sec: 130.999\n","INFO:tensorflow:loss = 21.367388, step = 6501 (0.766 sec)\n","INFO:tensorflow:global_step/sec: 144.152\n","INFO:tensorflow:loss = 7.3519006, step = 6601 (0.695 sec)\n","INFO:tensorflow:global_step/sec: 141.56\n","INFO:tensorflow:loss = 7.4022703, step = 6701 (0.705 sec)\n","INFO:tensorflow:global_step/sec: 132.301\n","INFO:tensorflow:loss = 8.117143, step = 6801 (0.757 sec)\n","INFO:tensorflow:global_step/sec: 141.935\n","INFO:tensorflow:loss = 10.749684, step = 6901 (0.702 sec)\n","INFO:tensorflow:global_step/sec: 133.531\n","INFO:tensorflow:loss = 3.2729735, step = 7001 (0.752 sec)\n","INFO:tensorflow:global_step/sec: 140.366\n","INFO:tensorflow:loss = 16.276453, step = 7101 (0.711 sec)\n","INFO:tensorflow:global_step/sec: 142.118\n","INFO:tensorflow:loss = 6.1992416, step = 7201 (0.704 sec)\n","INFO:tensorflow:global_step/sec: 131.523\n","INFO:tensorflow:loss = 3.3308473, step = 7301 (0.756 sec)\n","INFO:tensorflow:global_step/sec: 143.432\n","INFO:tensorflow:loss = 7.1785088, step = 7401 (0.701 sec)\n","INFO:tensorflow:global_step/sec: 131.472\n","INFO:tensorflow:loss = 6.130182, step = 7501 (0.760 sec)\n","INFO:tensorflow:global_step/sec: 141.074\n","INFO:tensorflow:loss = 4.001555, step = 7601 (0.709 sec)\n","INFO:tensorflow:global_step/sec: 140.927\n","INFO:tensorflow:loss = 6.928697, step = 7701 (0.706 sec)\n","INFO:tensorflow:global_step/sec: 128.933\n","INFO:tensorflow:loss = 7.856513, step = 7801 (0.780 sec)\n","INFO:tensorflow:global_step/sec: 141.376\n","INFO:tensorflow:loss = 21.463127, step = 7901 (0.707 sec)\n","INFO:tensorflow:global_step/sec: 133.309\n","INFO:tensorflow:loss = 5.552739, step = 8001 (0.749 sec)\n","INFO:tensorflow:global_step/sec: 144.427\n","INFO:tensorflow:loss = 8.910124, step = 8101 (0.690 sec)\n","INFO:tensorflow:global_step/sec: 140.062\n","INFO:tensorflow:loss = 6.5292478, step = 8201 (0.718 sec)\n","INFO:tensorflow:global_step/sec: 130.081\n","INFO:tensorflow:loss = 4.5228033, step = 8301 (0.766 sec)\n","INFO:tensorflow:global_step/sec: 142.06\n","INFO:tensorflow:loss = 3.4075668, step = 8401 (0.706 sec)\n","INFO:tensorflow:global_step/sec: 131.939\n","INFO:tensorflow:loss = 5.615141, step = 8501 (0.754 sec)\n","INFO:tensorflow:global_step/sec: 144.33\n","INFO:tensorflow:loss = 3.5260913, step = 8601 (0.695 sec)\n","INFO:tensorflow:global_step/sec: 142.174\n","INFO:tensorflow:loss = 2.9403725, step = 8701 (0.705 sec)\n","INFO:tensorflow:global_step/sec: 132.676\n","INFO:tensorflow:loss = 4.765787, step = 8801 (0.750 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 143.552\n","INFO:tensorflow:loss = 4.8809814, step = 8901 (0.699 sec)\n","INFO:tensorflow:global_step/sec: 131.184\n","INFO:tensorflow:loss = 3.7983847, step = 9001 (0.764 sec)\n","INFO:tensorflow:global_step/sec: 143.198\n","INFO:tensorflow:loss = 2.1459122, step = 9101 (0.699 sec)\n","INFO:tensorflow:global_step/sec: 143.496\n","INFO:tensorflow:loss = 7.8990154, step = 9201 (0.697 sec)\n","INFO:tensorflow:global_step/sec: 130.354\n","INFO:tensorflow:loss = 2.3313699, step = 9301 (0.768 sec)\n","INFO:tensorflow:global_step/sec: 141.814\n","INFO:tensorflow:loss = 5.4683466, step = 9401 (0.704 sec)\n","INFO:tensorflow:global_step/sec: 129.437\n","INFO:tensorflow:loss = 7.235301, step = 9501 (0.771 sec)\n","INFO:tensorflow:global_step/sec: 144.667\n","INFO:tensorflow:loss = 5.264308, step = 9601 (0.691 sec)\n","INFO:tensorflow:global_step/sec: 142.952\n","INFO:tensorflow:loss = 6.0005836, step = 9701 (0.700 sec)\n","INFO:tensorflow:global_step/sec: 132.833\n","INFO:tensorflow:loss = 5.7096004, step = 9801 (0.752 sec)\n","INFO:tensorflow:global_step/sec: 143.83\n","INFO:tensorflow:loss = 6.0469694, step = 9901 (0.699 sec)\n","INFO:tensorflow:global_step/sec: 129.443\n","INFO:tensorflow:loss = 3.717539, step = 10001 (0.769 sec)\n","INFO:tensorflow:global_step/sec: 142.281\n","INFO:tensorflow:loss = 5.660154, step = 10101 (0.700 sec)\n","INFO:tensorflow:global_step/sec: 146.067\n","INFO:tensorflow:loss = 17.715565, step = 10201 (0.687 sec)\n","INFO:tensorflow:global_step/sec: 131.439\n","INFO:tensorflow:loss = 3.5073547, step = 10301 (0.761 sec)\n","INFO:tensorflow:global_step/sec: 141.96\n","INFO:tensorflow:loss = 3.2643154, step = 10401 (0.707 sec)\n","INFO:tensorflow:global_step/sec: 133.395\n","INFO:tensorflow:loss = 1.5961365, step = 10501 (0.749 sec)\n","INFO:tensorflow:global_step/sec: 144.184\n","INFO:tensorflow:loss = 5.12188, step = 10601 (0.693 sec)\n","INFO:tensorflow:global_step/sec: 141.313\n","INFO:tensorflow:loss = 3.119621, step = 10701 (0.708 sec)\n","INFO:tensorflow:global_step/sec: 133.362\n","INFO:tensorflow:loss = 7.258956, step = 10801 (0.750 sec)\n","INFO:tensorflow:global_step/sec: 143.441\n","INFO:tensorflow:loss = 5.5506935, step = 10901 (0.699 sec)\n","INFO:tensorflow:global_step/sec: 132.577\n","INFO:tensorflow:loss = 1.8857992, step = 11001 (0.753 sec)\n","INFO:tensorflow:global_step/sec: 145.107\n","INFO:tensorflow:loss = 1.791135, step = 11101 (0.686 sec)\n","INFO:tensorflow:global_step/sec: 142.687\n","INFO:tensorflow:loss = 3.814642, step = 11201 (0.700 sec)\n","INFO:tensorflow:global_step/sec: 132.812\n","INFO:tensorflow:loss = 4.6870522, step = 11301 (0.754 sec)\n","INFO:tensorflow:global_step/sec: 142.994\n","INFO:tensorflow:loss = 6.2958684, step = 11401 (0.698 sec)\n","INFO:tensorflow:global_step/sec: 128.105\n","INFO:tensorflow:loss = 2.2229655, step = 11501 (0.784 sec)\n","INFO:tensorflow:global_step/sec: 142.331\n","INFO:tensorflow:loss = 8.347272, step = 11601 (0.698 sec)\n","INFO:tensorflow:global_step/sec: 142.667\n","INFO:tensorflow:loss = 1.8190604, step = 11701 (0.701 sec)\n","INFO:tensorflow:global_step/sec: 132.598\n","INFO:tensorflow:loss = 1.784062, step = 11801 (0.758 sec)\n","INFO:tensorflow:global_step/sec: 142.972\n","INFO:tensorflow:loss = 2.2418945, step = 11901 (0.696 sec)\n","INFO:tensorflow:global_step/sec: 131.436\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 2.8199995, step = 12001 (0.765 sec)\n","INFO:tensorflow:global_step/sec: 142.567\n","INFO:tensorflow:loss = 2.3412971, step = 12101 (0.701 sec)\n","INFO:tensorflow:global_step/sec: 141.496\n","INFO:tensorflow:loss = 2.495934, step = 12201 (0.706 sec)\n","INFO:tensorflow:global_step/sec: 132.133\n","INFO:tensorflow:loss = 4.003313, step = 12301 (0.763 sec)\n","INFO:tensorflow:global_step/sec: 140.433\n","INFO:tensorflow:loss = 3.3302722, step = 12401 (0.706 sec)\n","INFO:tensorflow:global_step/sec: 132.325\n","INFO:tensorflow:loss = 2.2496274, step = 12501 (0.757 sec)\n","INFO:tensorflow:global_step/sec: 142.474\n","INFO:tensorflow:loss = 5.928902, step = 12601 (0.702 sec)\n","INFO:tensorflow:global_step/sec: 143.898\n","INFO:tensorflow:loss = 1.9211568, step = 12701 (0.695 sec)\n","INFO:tensorflow:global_step/sec: 132.925\n","INFO:tensorflow:loss = 8.313526, step = 12801 (0.753 sec)\n","INFO:tensorflow:global_step/sec: 141.512\n","INFO:tensorflow:loss = 7.007321, step = 12901 (0.704 sec)\n","INFO:tensorflow:global_step/sec: 132.276\n","INFO:tensorflow:loss = 10.585957, step = 13001 (0.756 sec)\n","INFO:tensorflow:global_step/sec: 142.949\n","INFO:tensorflow:loss = 6.8558674, step = 13101 (0.697 sec)\n","INFO:tensorflow:global_step/sec: 143.304\n","INFO:tensorflow:loss = 3.919004, step = 13201 (0.703 sec)\n","INFO:tensorflow:global_step/sec: 133.744\n","INFO:tensorflow:loss = 4.8280516, step = 13301 (0.745 sec)\n","INFO:tensorflow:global_step/sec: 142.194\n","INFO:tensorflow:loss = 1.7102531, step = 13401 (0.705 sec)\n","INFO:tensorflow:global_step/sec: 132.692\n","INFO:tensorflow:loss = 8.5754385, step = 13501 (0.753 sec)\n","INFO:tensorflow:global_step/sec: 139.482\n","INFO:tensorflow:loss = 1.9001195, step = 13601 (0.718 sec)\n","INFO:tensorflow:global_step/sec: 141.862\n","INFO:tensorflow:loss = 0.51157403, step = 13701 (0.705 sec)\n","INFO:tensorflow:global_step/sec: 133.463\n","INFO:tensorflow:loss = 2.5364532, step = 13801 (0.745 sec)\n","INFO:tensorflow:global_step/sec: 142.227\n","INFO:tensorflow:loss = 3.1444252, step = 13901 (0.707 sec)\n","INFO:tensorflow:global_step/sec: 130.741\n","INFO:tensorflow:loss = 0.2952274, step = 14001 (0.766 sec)\n","INFO:tensorflow:global_step/sec: 141.942\n","INFO:tensorflow:loss = 3.5436926, step = 14101 (0.705 sec)\n","INFO:tensorflow:global_step/sec: 139.433\n","INFO:tensorflow:loss = 1.8293298, step = 14201 (0.713 sec)\n","INFO:tensorflow:global_step/sec: 132.107\n","INFO:tensorflow:loss = 2.7220335, step = 14301 (0.758 sec)\n","INFO:tensorflow:global_step/sec: 140.878\n","INFO:tensorflow:loss = 5.096092, step = 14401 (0.710 sec)\n","INFO:tensorflow:global_step/sec: 134.708\n","INFO:tensorflow:loss = 0.37946975, step = 14501 (0.744 sec)\n","INFO:tensorflow:global_step/sec: 143.308\n","INFO:tensorflow:loss = 2.3634238, step = 14601 (0.695 sec)\n","INFO:tensorflow:global_step/sec: 142.514\n","INFO:tensorflow:loss = 0.71576524, step = 14701 (0.704 sec)\n","INFO:tensorflow:global_step/sec: 131.548\n","INFO:tensorflow:loss = 0.6241527, step = 14801 (0.761 sec)\n","INFO:tensorflow:global_step/sec: 141.334\n","INFO:tensorflow:loss = 1.3545704, step = 14901 (0.707 sec)\n","INFO:tensorflow:global_step/sec: 132.464\n","INFO:tensorflow:loss = 0.5844655, step = 15001 (0.756 sec)\n","INFO:tensorflow:global_step/sec: 142.028\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.7465215, step = 15101 (0.703 sec)\n","INFO:tensorflow:global_step/sec: 142.912\n","INFO:tensorflow:loss = 4.4158926, step = 15201 (0.700 sec)\n","INFO:tensorflow:global_step/sec: 133.474\n","INFO:tensorflow:loss = 1.6503565, step = 15301 (0.747 sec)\n","INFO:tensorflow:global_step/sec: 139.868\n","INFO:tensorflow:loss = 3.512095, step = 15401 (0.716 sec)\n","INFO:tensorflow:global_step/sec: 130.768\n","INFO:tensorflow:loss = 0.54446685, step = 15501 (0.765 sec)\n","INFO:tensorflow:global_step/sec: 138.041\n","INFO:tensorflow:loss = 8.183871, step = 15601 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 145.05\n","INFO:tensorflow:loss = 1.1360481, step = 15701 (0.687 sec)\n","INFO:tensorflow:global_step/sec: 129.385\n","INFO:tensorflow:loss = 1.0725486, step = 15801 (0.776 sec)\n","INFO:tensorflow:global_step/sec: 145.299\n","INFO:tensorflow:loss = 2.489804, step = 15901 (0.689 sec)\n","INFO:tensorflow:global_step/sec: 134.499\n","INFO:tensorflow:loss = 2.422391, step = 16001 (0.744 sec)\n","INFO:tensorflow:global_step/sec: 140.322\n","INFO:tensorflow:loss = 5.0453267, step = 16101 (0.711 sec)\n","INFO:tensorflow:global_step/sec: 138.875\n","INFO:tensorflow:loss = 2.3702757, step = 16201 (0.719 sec)\n","INFO:tensorflow:global_step/sec: 131.688\n","INFO:tensorflow:loss = 3.9339795, step = 16301 (0.761 sec)\n","INFO:tensorflow:global_step/sec: 144.458\n","INFO:tensorflow:loss = 1.729793, step = 16401 (0.694 sec)\n","INFO:tensorflow:global_step/sec: 129.737\n","INFO:tensorflow:loss = 2.3372185, step = 16501 (0.768 sec)\n","INFO:tensorflow:global_step/sec: 143.25\n","INFO:tensorflow:loss = 0.97273016, step = 16601 (0.700 sec)\n","INFO:tensorflow:global_step/sec: 144.386\n","INFO:tensorflow:loss = 3.632445, step = 16701 (0.693 sec)\n","INFO:tensorflow:global_step/sec: 131.126\n","INFO:tensorflow:loss = 2.6861885, step = 16801 (0.763 sec)\n","INFO:tensorflow:global_step/sec: 144.271\n","INFO:tensorflow:loss = 1.3237467, step = 16901 (0.692 sec)\n","INFO:tensorflow:global_step/sec: 130.666\n","INFO:tensorflow:loss = 0.54732835, step = 17001 (0.765 sec)\n","INFO:tensorflow:global_step/sec: 140.468\n","INFO:tensorflow:loss = 1.5887246, step = 17101 (0.708 sec)\n","INFO:tensorflow:global_step/sec: 140.558\n","INFO:tensorflow:loss = 0.8719629, step = 17201 (0.717 sec)\n","INFO:tensorflow:global_step/sec: 132.517\n","INFO:tensorflow:loss = 0.560125, step = 17301 (0.751 sec)\n","INFO:tensorflow:global_step/sec: 140.989\n","INFO:tensorflow:loss = 1.3914913, step = 17401 (0.711 sec)\n","INFO:tensorflow:global_step/sec: 132.422\n","INFO:tensorflow:loss = 0.72042084, step = 17501 (0.755 sec)\n","INFO:tensorflow:global_step/sec: 143.606\n","INFO:tensorflow:loss = 7.8624296, step = 17601 (0.694 sec)\n","INFO:tensorflow:global_step/sec: 142.277\n","INFO:tensorflow:loss = 0.50473887, step = 17701 (0.703 sec)\n","INFO:tensorflow:global_step/sec: 132.345\n","INFO:tensorflow:loss = 2.099638, step = 17801 (0.757 sec)\n","INFO:tensorflow:global_step/sec: 144.008\n","INFO:tensorflow:loss = 4.8494244, step = 17901 (0.695 sec)\n","INFO:tensorflow:global_step/sec: 129.825\n","INFO:tensorflow:loss = 1.1451732, step = 18001 (0.772 sec)\n","INFO:tensorflow:global_step/sec: 141.546\n","INFO:tensorflow:loss = 2.356175, step = 18101 (0.705 sec)\n","INFO:tensorflow:global_step/sec: 140.114\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.9214001, step = 18201 (0.714 sec)\n","INFO:tensorflow:global_step/sec: 135.378\n","INFO:tensorflow:loss = 3.4166985, step = 18301 (0.740 sec)\n","INFO:tensorflow:global_step/sec: 147.175\n","INFO:tensorflow:loss = 5.8715305, step = 18401 (0.676 sec)\n","INFO:tensorflow:global_step/sec: 132.168\n","INFO:tensorflow:loss = 1.6303307, step = 18501 (0.759 sec)\n","INFO:tensorflow:global_step/sec: 143.379\n","INFO:tensorflow:loss = 0.2981727, step = 18601 (0.698 sec)\n","INFO:tensorflow:global_step/sec: 136.011\n","INFO:tensorflow:loss = 0.9209101, step = 18701 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 132.419\n","INFO:tensorflow:loss = 3.7313564, step = 18801 (0.755 sec)\n","INFO:tensorflow:global_step/sec: 142.633\n","INFO:tensorflow:loss = 0.19481394, step = 18901 (0.702 sec)\n","INFO:tensorflow:global_step/sec: 130.875\n","INFO:tensorflow:loss = 1.690991, step = 19001 (0.759 sec)\n","INFO:tensorflow:global_step/sec: 141.94\n","INFO:tensorflow:loss = 4.5606117, step = 19101 (0.705 sec)\n","INFO:tensorflow:global_step/sec: 141.255\n","INFO:tensorflow:loss = 1.771851, step = 19201 (0.708 sec)\n","INFO:tensorflow:global_step/sec: 132.289\n","INFO:tensorflow:loss = 0.8954933, step = 19301 (0.760 sec)\n","INFO:tensorflow:global_step/sec: 138.614\n","INFO:tensorflow:loss = 7.798374, step = 19401 (0.721 sec)\n","INFO:tensorflow:global_step/sec: 133.264\n","INFO:tensorflow:loss = 4.2798405, step = 19501 (0.750 sec)\n","INFO:tensorflow:global_step/sec: 142.67\n","INFO:tensorflow:loss = 0.12966156, step = 19601 (0.699 sec)\n","INFO:tensorflow:global_step/sec: 142.944\n","INFO:tensorflow:loss = 4.0670013, step = 19701 (0.703 sec)\n","INFO:tensorflow:global_step/sec: 132.009\n","INFO:tensorflow:loss = 0.9879393, step = 19801 (0.756 sec)\n","INFO:tensorflow:global_step/sec: 143.174\n","INFO:tensorflow:loss = 1.8223519, step = 19901 (0.700 sec)\n","INFO:tensorflow:global_step/sec: 131.315\n","INFO:tensorflow:loss = 2.3973405, step = 20001 (0.761 sec)\n","INFO:tensorflow:global_step/sec: 137.71\n","INFO:tensorflow:loss = 0.47258544, step = 20101 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 142.524\n","INFO:tensorflow:loss = 1.4738759, step = 20201 (0.705 sec)\n","INFO:tensorflow:global_step/sec: 133.872\n","INFO:tensorflow:loss = 5.432727, step = 20301 (0.748 sec)\n","INFO:tensorflow:global_step/sec: 144.098\n","INFO:tensorflow:loss = 0.5664751, step = 20401 (0.689 sec)\n","INFO:tensorflow:global_step/sec: 130.892\n","INFO:tensorflow:loss = 0.1374355, step = 20501 (0.768 sec)\n","INFO:tensorflow:global_step/sec: 141.454\n","INFO:tensorflow:loss = 0.7835665, step = 20601 (0.704 sec)\n","INFO:tensorflow:global_step/sec: 141.358\n","INFO:tensorflow:loss = 3.0061486, step = 20701 (0.710 sec)\n","INFO:tensorflow:global_step/sec: 130.885\n","INFO:tensorflow:loss = 3.2850757, step = 20801 (0.764 sec)\n","INFO:tensorflow:global_step/sec: 138.898\n","INFO:tensorflow:loss = 1.1341922, step = 20901 (0.718 sec)\n","INFO:tensorflow:global_step/sec: 131.952\n","INFO:tensorflow:loss = 2.0339463, step = 21001 (0.758 sec)\n","INFO:tensorflow:global_step/sec: 142.996\n","INFO:tensorflow:loss = 4.0417376, step = 21101 (0.700 sec)\n","INFO:tensorflow:global_step/sec: 144.788\n","INFO:tensorflow:loss = 1.8937935, step = 21201 (0.693 sec)\n","INFO:tensorflow:global_step/sec: 133.598\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 4.2388797, step = 21301 (0.749 sec)\n","INFO:tensorflow:global_step/sec: 144.049\n","INFO:tensorflow:loss = 3.5011063, step = 21401 (0.692 sec)\n","INFO:tensorflow:global_step/sec: 132.815\n","INFO:tensorflow:loss = 0.77983075, step = 21501 (0.752 sec)\n","INFO:tensorflow:global_step/sec: 139.289\n","INFO:tensorflow:loss = 11.005305, step = 21601 (0.717 sec)\n","INFO:tensorflow:global_step/sec: 141.116\n","INFO:tensorflow:loss = 1.6729821, step = 21701 (0.710 sec)\n","INFO:tensorflow:global_step/sec: 132.783\n","INFO:tensorflow:loss = 0.12548988, step = 21801 (0.754 sec)\n","INFO:tensorflow:global_step/sec: 143.661\n","INFO:tensorflow:loss = 2.0530326, step = 21901 (0.696 sec)\n","INFO:tensorflow:global_step/sec: 131.285\n","INFO:tensorflow:loss = 4.871589, step = 22001 (0.761 sec)\n","INFO:tensorflow:global_step/sec: 141.074\n","INFO:tensorflow:loss = 1.0553699, step = 22101 (0.707 sec)\n","INFO:tensorflow:global_step/sec: 143.315\n","INFO:tensorflow:loss = 7.012484, step = 22201 (0.700 sec)\n","INFO:tensorflow:global_step/sec: 129.814\n","INFO:tensorflow:loss = 0.34771842, step = 22301 (0.771 sec)\n","INFO:tensorflow:global_step/sec: 142.661\n","INFO:tensorflow:loss = 0.60208446, step = 22401 (0.697 sec)\n","INFO:tensorflow:global_step/sec: 132.141\n","INFO:tensorflow:loss = 1.7584879, step = 22501 (0.756 sec)\n","INFO:tensorflow:global_step/sec: 141.769\n","INFO:tensorflow:loss = 0.32047015, step = 22601 (0.705 sec)\n","INFO:tensorflow:global_step/sec: 144.745\n","INFO:tensorflow:loss = 2.9696164, step = 22701 (0.696 sec)\n","INFO:tensorflow:global_step/sec: 130.001\n","INFO:tensorflow:loss = 1.0677983, step = 22801 (0.771 sec)\n","INFO:tensorflow:global_step/sec: 142.551\n","INFO:tensorflow:loss = 0.74583393, step = 22901 (0.697 sec)\n","INFO:tensorflow:global_step/sec: 129.577\n","INFO:tensorflow:loss = 3.8385262, step = 23001 (0.774 sec)\n","INFO:tensorflow:global_step/sec: 141.756\n","INFO:tensorflow:loss = 4.218362, step = 23101 (0.705 sec)\n","INFO:tensorflow:global_step/sec: 142.579\n","INFO:tensorflow:loss = 1.4483066, step = 23201 (0.699 sec)\n","INFO:tensorflow:global_step/sec: 131.206\n","INFO:tensorflow:loss = 2.7933292, step = 23301 (0.762 sec)\n","INFO:tensorflow:global_step/sec: 145.186\n","INFO:tensorflow:loss = 1.6482353, step = 23401 (0.690 sec)\n","INFO:tensorflow:global_step/sec: 131.577\n","INFO:tensorflow:loss = 2.126793, step = 23501 (0.761 sec)\n","INFO:tensorflow:global_step/sec: 142.907\n","INFO:tensorflow:loss = 3.679379, step = 23601 (0.695 sec)\n","INFO:tensorflow:global_step/sec: 143.276\n","INFO:tensorflow:loss = 0.15039529, step = 23701 (0.702 sec)\n","INFO:tensorflow:global_step/sec: 127.214\n","INFO:tensorflow:loss = 0.55176055, step = 23801 (0.785 sec)\n","INFO:tensorflow:global_step/sec: 139.713\n","INFO:tensorflow:loss = 0.21983466, step = 23901 (0.716 sec)\n","INFO:tensorflow:global_step/sec: 134.046\n","INFO:tensorflow:loss = 4.352503, step = 24001 (0.746 sec)\n","INFO:tensorflow:global_step/sec: 143.629\n","INFO:tensorflow:loss = 0.490341, step = 24101 (0.696 sec)\n","INFO:tensorflow:global_step/sec: 140.935\n","INFO:tensorflow:loss = 1.1461806, step = 24201 (0.707 sec)\n","INFO:tensorflow:global_step/sec: 131.69\n","INFO:tensorflow:loss = 0.25768784, step = 24301 (0.764 sec)\n","INFO:tensorflow:global_step/sec: 142.239\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 3.4670062, step = 24401 (0.706 sec)\n","INFO:tensorflow:global_step/sec: 129.737\n","INFO:tensorflow:loss = 0.9063788, step = 24501 (0.769 sec)\n","INFO:tensorflow:global_step/sec: 142.487\n","INFO:tensorflow:loss = 0.22987898, step = 24601 (0.701 sec)\n","INFO:tensorflow:global_step/sec: 141.662\n","INFO:tensorflow:loss = 0.07385022, step = 24701 (0.706 sec)\n","INFO:tensorflow:global_step/sec: 132.783\n","INFO:tensorflow:loss = 3.4291701, step = 24801 (0.753 sec)\n","INFO:tensorflow:global_step/sec: 142.372\n","INFO:tensorflow:loss = 5.764145, step = 24901 (0.703 sec)\n","INFO:tensorflow:Saving checkpoints for 25000 into /tmp/tmppw5q4h5g/cnn/model.ckpt.\n","INFO:tensorflow:Loss for final step: 0.7629983.\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2018-03-06-17:01:33\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmppw5q4h5g/cnn/model.ckpt-25000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Finished evaluation at 2018-03-06-17:01:35\n","INFO:tensorflow:Saving dict for global step 25000: accuracy = 0.86732, accuracy_baseline = 0.5, auc = 0.9186778, auc_precision_recall = 0.9267081, average_loss = 0.75591916, global_step = 25000, label/mean = 0.5, loss = 75.59191, prediction/mean = 0.5262949\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmppw5q4h5g/cnn/model.ckpt-25000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"}]},{"metadata":{"id":"7Smc5jUdt6SL","colab_type":"text"},"cell_type":"markdown","source":["###Â LSTM Networks\n","\n","Using the `Estimator` API and the same model `head`, we can also create a classifier that uses a *Long Short-Term Memory* (*LSTM*) cell instead of convolutions. Recurrent models such as this are some of the most successful building blocks for NLP applications. An LSTM processes the entire document sequentially, recursing over the sequence with its cell while storing the current state of the sequence in its memory.\n","\n","One of the drawbacks of recurrent models compared to CNNs is that, because of the nature of recursion, models are deeper and more complex, which usually results in slower training time and worse convergence. LSTMs (and RNNs in general) can suffer convergence issues like vanishing or exploding gradients. Having said that, with sufficient tuning they obtain state-of-the-art results for many problems. As a rule of thumb, CNNs are good at feature extraction, while RNNs excel at tasks that depend on the meaning of the whole sentence, like question answering or machine translation.\n","\n","Each cell processes one token embedding at a time updating its internal state based on a differentiable computation that depends on both the embedding vector $x_t$ and the previous state $h_{t-1}$. In order to get a better understanding of how LSTMs work, you can refer to Chris Olahâs [blog post](https://colah.github.io/posts/2015-08-Understanding-LSTMs/).\n","\n","![LSTM Architecture](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png)\n","<small><p align=\"center\">\n","Source: <a href=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/\">Understanding LSTM Networks</a> by <strong>Chris Olah</strong>\n","</p></small>\n","\n","In the beginning of this notebook, we padded all documents up to $200$ tokens, which is necessary to build a proper tensor. However, when a document contains fewer than $200$ words, we don't want the LSTM to continue processing padding tokens as it does not add information and degrades performance. For this reason, we additionally want to provide our network with the length of the original sequence before it was padded. Internally, the model then copies the last state through to the sequence's end. We can do this by using the `\"len\"` feature in our input functions. We can now use the same logic as above and simply replace the convolutional, pooling, and flatten layers with our LSTM cell."]},{"metadata":{"id":"a6PDOS-d0gBN","colab_type":"text"},"cell_type":"markdown","source":["We can use the same logic as above and simply need to replace the convolutional, pooling, and flatten layers with our LSTM cell."]},{"metadata":{"id":"QSNT9KXtt_Up","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":911},"outputId":"dfbaee5e-3b3d-4c2a-db64-9b3350acdf65","executionInfo":{"status":"ok","timestamp":1520289526441,"user_tz":180,"elapsed":215179,"user":{"displayName":"Julian Eisenschlos","photoUrl":"//lh3.googleusercontent.com/-64ZxueD_a5k/AAAAAAAAAAI/AAAAAAAAY_I/SjD0k9jJ8Ug/s50-c-k-no/photo.jpg","userId":"112692138304087361987"}}},"cell_type":"code","source":["head = tf.contrib.estimator.binary_classification_head()\n","\n","def lstm_model_fn(features, labels, mode):    \n","    # [batch_size x sentence_size x embedding_size]\n","    inputs = tf.contrib.layers.embed_sequence(\n","        features['x'], vocab_size, embedding_size,\n","        initializer=tf.random_uniform_initializer(-1.0, 1.0))\n","\n","    # create an LSTM cell of size 100\n","    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(100)\n","    \n","    # create the complete LSTM\n","    _, final_states = tf.nn.dynamic_rnn(\n","        lstm_cell, inputs, sequence_length=features['len'], dtype=tf.float32)\n","\n","    # get the final hidden states of dimensionality [batch_size x sentence_size]\n","    outputs = final_states.h\n","\n","    logits = tf.layers.dense(inputs=outputs, units=1)\n","\n","    # This will be None when predicting\n","    if labels is not None:\n","        labels = tf.reshape(labels, [-1, 1])\n","\n","    optimizer = tf.train.AdamOptimizer()\n","\n","    def _train_op_fn(loss):\n","        return optimizer.minimize(\n","            loss=loss,\n","            global_step=tf.train.get_global_step())\n","\n","    return head.create_estimator_spec(\n","        features=features,\n","        labels=labels,\n","        mode=mode,\n","        logits=logits,\n","        train_op_fn=_train_op_fn)\n","\n","\n","lstm_classifier = tf.estimator.Estimator(model_fn=lstm_model_fn,\n","                                         model_dir=os.path.join(model_dir, 'lstm'))\n","train_and_evaluate(lstm_classifier)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using default config.\n","INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpypwz2ae9/lstm', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff12e45a0b8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpypwz2ae9/lstm/model.ckpt-24338\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 24339 into /tmp/tmpypwz2ae9/lstm/model.ckpt.\n","INFO:tensorflow:loss = 0.0059510386, step = 24339\n","INFO:tensorflow:global_step/sec: 3.72307\n","INFO:tensorflow:loss = 0.0033893716, step = 24439 (26.866 sec)\n","INFO:tensorflow:Saving checkpoints for 24538 into /tmp/tmpypwz2ae9/lstm/model.ckpt.\n","INFO:tensorflow:Loss for final step: 0.001164208.\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2018-03-05-22:36:17\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpypwz2ae9/lstm/model.ckpt-24538\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Finished evaluation at 2018-03-05-22:36:52\n","INFO:tensorflow:Saving dict for global step 24538: accuracy = 0.86808, accuracy_baseline = 0.5, auc = 0.89402777, auc_precision_recall = 0.9138372, average_loss = 1.2736638, global_step = 24538, label/mean = 0.5, loss = 127.36638, prediction/mean = 0.5032062\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpypwz2ae9/lstm/model.ckpt-24538\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","  adding: tmp/tmpypwz2ae9/lstm/ (stored 0%)\n","  adding: tmp/tmpypwz2ae9/lstm/graph.pbtxt (deflated 89%)\n","  adding: tmp/tmpypwz2ae9/lstm/events.out.tfevents.1520281837.86f86223cf96 (deflated 69%)\n","  adding: tmp/tmpypwz2ae9/lstm/model.ckpt-22112.data-00000-of-00001 (deflated 7%)\n","  adding: tmp/tmpypwz2ae9/lstm/model.ckpt-22112.meta (deflated 69%)\n","  adding: tmp/tmpypwz2ae9/lstm/model.ckpt-24338.data-00000-of-00001 (deflated 7%)\n","  adding: tmp/tmpypwz2ae9/lstm/model.ckpt-19890.meta (deflated 69%)\n","  adding: tmp/tmpypwz2ae9/lstm/model.ckpt-24538.meta (deflated 69%)\n","  adding: tmp/tmpypwz2ae9/lstm/model.ckpt-24339.meta (deflated 69%)\n","  adding: tmp/tmpypwz2ae9/lstm/model.ckpt-24339.data-00000-of-00001 (deflated 7%)\n","  adding: tmp/tmpypwz2ae9/lstm/model.ckpt-24538.data-00000-of-00001 (deflated 7%)\n","  adding: tmp/tmpypwz2ae9/lstm/eval/ (stored 0%)\n","  adding: tmp/tmpypwz2ae9/lstm/eval/events.out.tfevents.1520289447.86f86223cf96 (deflated 47%)\n","  adding: tmp/tmpypwz2ae9/lstm/eval/events.out.tfevents.1520289412.86f86223cf96 (deflated 70%)\n","  adding: tmp/tmpypwz2ae9/lstm/model.ckpt-24538.index (deflated 37%)\n","  adding: tmp/tmpypwz2ae9/lstm/model.ckpt-19890.data-00000-of-00001 (deflated 7%)\n","  adding: tmp/tmpypwz2ae9/lstm/model.ckpt-24339.index (deflated 37%)\n","  adding: tmp/tmpypwz2ae9/lstm/model.ckpt-22112.index (deflated 37%)\n","  adding: tmp/tmpypwz2ae9/lstm/model.ckpt-19890.index (deflated 37%)\n","  adding: tmp/tmpypwz2ae9/lstm/model.ckpt-24338.index (deflated 37%)\n","  adding: tmp/tmpypwz2ae9/lstm/checkpoint (deflated 72%)\n","  adding: tmp/tmpypwz2ae9/lstm/model.ckpt-24338.meta (deflated 69%)\n"],"name":"stdout"}]},{"metadata":{"id":"E-wDDowAvq-X","colab_type":"text"},"cell_type":"markdown","source":["### Pretrained vectors\n","\n","Most of the models that we have shown before rely on word embeddings as a first layer, and we have so far initialized this embedding layer randomly, however it has been shown [in](https://arxiv.org/abs/1607.01759) [the](https://arxiv.org/abs/1301.3781) [literature](https://arxiv.org/abs/1103.0398), that especially for small labelled datasets, it is beneficial to train a pretrain word embeddings on a large unlabelled corpora using an unsupervised task. One such task is shown [here](https://www.tensorflow.org/tutorials/word2vec). This technique is an instance of *transfer learning*.\n","\n","To this end, we will show you how to use them in an `Estimator`. We will use the pre-trained vectors from another popular model, [GloVe](https://nlp.stanford.edu/projects/glove/).\n","\n","We download the pretrained vectors and define a function that loads them into a `numpy.array`."]},{"metadata":{"id":"7zbWoklJtzRP","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":377},"outputId":"a03a4db2-cc6a-4a43-8f5d-c4aeac7c00be","executionInfo":{"status":"ok","timestamp":1520355813761,"user_tz":0,"elapsed":116108,"user":{"displayName":"Sebastian Ruder","photoUrl":"//lh5.googleusercontent.com/-_RsKB476gus/AAAAAAAAAAI/AAAAAAAAVys/bDJNFfUAEUU/s50-c-k-no/photo.jpg","userId":"101962136952284559776"}}},"cell_type":"code","source":["if not os.path.exists('glove.6B.zip'):\n","    ! wget http://nlp.stanford.edu/data/glove.6B.zip\n","if not os.path.exists('glove.6B.50d.txt'):\n","    ! unzip glove.6B.zip"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2018-03-06 17:01:38--  http://nlp.stanford.edu/data/glove.6B.zip\r\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n","--2018-03-06 17:01:38--  https://nlp.stanford.edu/data/glove.6B.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 862182613 (822M) [application/zip]\n","Saving to: âglove.6B.zipâ\n","\n","glove.6B.zip         48%[========>           ] 397.21M  4.85MB/s    eta 32s    "],"name":"stdout"},{"output_type":"stream","text":["glove.6B.zip        100%[===================>] 822.24M  11.9MB/s    in 93s     \n","\n","2018-03-06 17:03:11 (8.88 MB/s) - âglove.6B.zipâ saved [862182613/862182613]\n","\n","Archive:  glove.6B.zip\n","  inflating: glove.6B.50d.txt        \n","  inflating: glove.6B.100d.txt       \n","  inflating: glove.6B.200d.txt       \n","  inflating: glove.6B.300d.txt       \n"],"name":"stdout"}]},{"metadata":{"id":"S5m1Fkj4vq-Y","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"5c525191-ae6f-45aa-9047-ea0510746451","executionInfo":{"status":"ok","timestamp":1520355821435,"user_tz":0,"elapsed":7587,"user":{"displayName":"Sebastian Ruder","photoUrl":"//lh5.googleusercontent.com/-_RsKB476gus/AAAAAAAAAAI/AAAAAAAAVys/bDJNFfUAEUU/s50-c-k-no/photo.jpg","userId":"101962136952284559776"}}},"cell_type":"code","source":["def load_glove_embeddings(path):\n","    embeddings = {}\n","    with open(path, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            values = line.strip().split()\n","            w = values[0]\n","            vectors = np.asarray(values[1:], dtype='float32')\n","            embeddings[w] = vectors\n","\n","    embedding_matrix = np.random.uniform(-1, 1, size=(vocab_size, embedding_size))\n","    num_loaded = 0\n","    for w, i in word_index.items():\n","        v = embeddings.get(w)\n","        if v is not None and i < vocab_size:\n","            embedding_matrix[i] = v\n","            num_loaded += 1\n","    print('Successfully loaded pretrained embeddings for '\n","          f'{num_loaded}/{vocab_size} words.')\n","    embedding_matrix = embedding_matrix.astype(np.float32)\n","    return embedding_matrix\n","\n","embedding_matrix = load_glove_embeddings('glove.6B.50d.txt')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Successfully loaded pretrained embeddings for 4920/5000 words.\n"],"name":"stdout"}]},{"metadata":{"id":"7LwE2M5kKY44","colab_type":"text"},"cell_type":"markdown","source":["To create a CNN classifier that leverages pretrained embeddings, we can reuse our `cnn_model_fn` but pass in a custom initializer that initializes the embeddings with our pretrained embedding matrix."]},{"metadata":{"id":"1uWwWkqjFbRE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":8962},"outputId":"466bc012-df13-428d-d91d-32aae3c51756","executionInfo":{"status":"ok","timestamp":1520356028896,"user_tz":0,"elapsed":206590,"user":{"displayName":"Sebastian Ruder","photoUrl":"//lh5.googleusercontent.com/-_RsKB476gus/AAAAAAAAAAI/AAAAAAAAVys/bDJNFfUAEUU/s50-c-k-no/photo.jpg","userId":"101962136952284559776"}}},"cell_type":"code","source":["def my_initializer(shape=None, dtype=tf.float32, partition_info=None):\n","    assert dtype is tf.float32\n","    return embedding_matrix\n","\n","params = {'embedding_initializer': my_initializer}\n","cnn_pretrained_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn,\n","                                        model_dir=os.path.join(model_dir, 'cnn_pretrained'),\n","                                        params=params)\n","train_and_evaluate(cnn_pretrained_classifier)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using default config.\n","INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmppw5q4h5g/cnn_pretrained', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff7fa967a58>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmppw5q4h5g/cnn_pretrained/model.ckpt.\n","INFO:tensorflow:loss = 76.006, step = 1\n","INFO:tensorflow:global_step/sec: 116.105\n","INFO:tensorflow:loss = 70.70961, step = 101 (0.867 sec)\n","INFO:tensorflow:global_step/sec: 130.745\n","INFO:tensorflow:loss = 65.575066, step = 201 (0.763 sec)\n","INFO:tensorflow:global_step/sec: 120.133\n","INFO:tensorflow:loss = 57.806713, step = 301 (0.835 sec)\n","INFO:tensorflow:global_step/sec: 132.162\n","INFO:tensorflow:loss = 47.23108, step = 401 (0.754 sec)\n","INFO:tensorflow:global_step/sec: 124.283\n","INFO:tensorflow:loss = 49.076565, step = 501 (0.807 sec)\n","INFO:tensorflow:global_step/sec: 129.659\n","INFO:tensorflow:loss = 50.298573, step = 601 (0.767 sec)\n","INFO:tensorflow:global_step/sec: 130.729\n","INFO:tensorflow:loss = 33.51182, step = 701 (0.770 sec)\n","INFO:tensorflow:global_step/sec: 122.259\n","INFO:tensorflow:loss = 34.39263, step = 801 (0.815 sec)\n","INFO:tensorflow:global_step/sec: 127.266\n","INFO:tensorflow:loss = 36.174633, step = 901 (0.788 sec)\n","INFO:tensorflow:global_step/sec: 123.539\n","INFO:tensorflow:loss = 22.10167, step = 1001 (0.809 sec)\n","INFO:tensorflow:global_step/sec: 130.02\n","INFO:tensorflow:loss = 33.962658, step = 1101 (0.767 sec)\n","INFO:tensorflow:global_step/sec: 131.713\n","INFO:tensorflow:loss = 31.124372, step = 1201 (0.761 sec)\n","INFO:tensorflow:global_step/sec: 121.485\n","INFO:tensorflow:loss = 25.367405, step = 1301 (0.824 sec)\n","INFO:tensorflow:global_step/sec: 134.253\n","INFO:tensorflow:loss = 38.212067, step = 1401 (0.744 sec)\n","INFO:tensorflow:global_step/sec: 122.078\n","INFO:tensorflow:loss = 26.813482, step = 1501 (0.821 sec)\n","INFO:tensorflow:global_step/sec: 130.85\n","INFO:tensorflow:loss = 34.094086, step = 1601 (0.759 sec)\n","INFO:tensorflow:global_step/sec: 131.274\n","INFO:tensorflow:loss = 20.105598, step = 1701 (0.768 sec)\n","INFO:tensorflow:global_step/sec: 121.68\n","INFO:tensorflow:loss = 23.064825, step = 1801 (0.816 sec)\n","INFO:tensorflow:global_step/sec: 131.876\n","INFO:tensorflow:loss = 42.26374, step = 1901 (0.762 sec)\n","INFO:tensorflow:global_step/sec: 123.468\n","INFO:tensorflow:loss = 27.369228, step = 2001 (0.814 sec)\n","INFO:tensorflow:global_step/sec: 133.669\n","INFO:tensorflow:loss = 24.066729, step = 2101 (0.745 sec)\n","INFO:tensorflow:global_step/sec: 134.044\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 28.029745, step = 2201 (0.747 sec)\n","INFO:tensorflow:global_step/sec: 122.326\n","INFO:tensorflow:loss = 27.09712, step = 2301 (0.815 sec)\n","INFO:tensorflow:global_step/sec: 133.161\n","INFO:tensorflow:loss = 35.560253, step = 2401 (0.751 sec)\n","INFO:tensorflow:global_step/sec: 125.566\n","INFO:tensorflow:loss = 23.276848, step = 2501 (0.794 sec)\n","INFO:tensorflow:global_step/sec: 132.372\n","INFO:tensorflow:loss = 16.987421, step = 2601 (0.760 sec)\n","INFO:tensorflow:global_step/sec: 135.813\n","INFO:tensorflow:loss = 15.646078, step = 2701 (0.736 sec)\n","INFO:tensorflow:global_step/sec: 124.599\n","INFO:tensorflow:loss = 11.777176, step = 2801 (0.800 sec)\n","INFO:tensorflow:global_step/sec: 134.424\n","INFO:tensorflow:loss = 32.319553, step = 2901 (0.744 sec)\n","INFO:tensorflow:global_step/sec: 124.247\n","INFO:tensorflow:loss = 16.529232, step = 3001 (0.807 sec)\n","INFO:tensorflow:global_step/sec: 134.814\n","INFO:tensorflow:loss = 17.815783, step = 3101 (0.741 sec)\n","INFO:tensorflow:global_step/sec: 133.891\n","INFO:tensorflow:loss = 14.177421, step = 3201 (0.746 sec)\n","INFO:tensorflow:global_step/sec: 127.18\n","INFO:tensorflow:loss = 18.537971, step = 3301 (0.789 sec)\n","INFO:tensorflow:global_step/sec: 134.617\n","INFO:tensorflow:loss = 17.580612, step = 3401 (0.742 sec)\n","INFO:tensorflow:global_step/sec: 124.392\n","INFO:tensorflow:loss = 22.312948, step = 3501 (0.804 sec)\n","INFO:tensorflow:global_step/sec: 135.973\n","INFO:tensorflow:loss = 19.526161, step = 3601 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 132.366\n","INFO:tensorflow:loss = 9.577492, step = 3701 (0.756 sec)\n","INFO:tensorflow:global_step/sec: 124.376\n","INFO:tensorflow:loss = 9.322842, step = 3801 (0.804 sec)\n","INFO:tensorflow:global_step/sec: 135.3\n","INFO:tensorflow:loss = 17.3103, step = 3901 (0.740 sec)\n","INFO:tensorflow:global_step/sec: 125.638\n","INFO:tensorflow:loss = 8.9027405, step = 4001 (0.796 sec)\n","INFO:tensorflow:global_step/sec: 134.676\n","INFO:tensorflow:loss = 10.144058, step = 4101 (0.738 sec)\n","INFO:tensorflow:global_step/sec: 133.33\n","INFO:tensorflow:loss = 13.834918, step = 4201 (0.750 sec)\n","INFO:tensorflow:global_step/sec: 124.202\n","INFO:tensorflow:loss = 10.913439, step = 4301 (0.810 sec)\n","INFO:tensorflow:global_step/sec: 134.847\n","INFO:tensorflow:loss = 11.695838, step = 4401 (0.741 sec)\n","INFO:tensorflow:global_step/sec: 126.221\n","INFO:tensorflow:loss = 18.810844, step = 4501 (0.790 sec)\n","INFO:tensorflow:global_step/sec: 134.352\n","INFO:tensorflow:loss = 20.45883, step = 4601 (0.743 sec)\n","INFO:tensorflow:global_step/sec: 135.552\n","INFO:tensorflow:loss = 7.503963, step = 4701 (0.740 sec)\n","INFO:tensorflow:global_step/sec: 124.394\n","INFO:tensorflow:loss = 17.212856, step = 4801 (0.804 sec)\n","INFO:tensorflow:global_step/sec: 136.071\n","INFO:tensorflow:loss = 11.046639, step = 4901 (0.737 sec)\n","INFO:tensorflow:global_step/sec: 123.799\n","INFO:tensorflow:loss = 13.302075, step = 5001 (0.806 sec)\n","INFO:tensorflow:global_step/sec: 136.766\n","INFO:tensorflow:loss = 18.5837, step = 5101 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 131.696\n","INFO:tensorflow:loss = 15.785164, step = 5201 (0.757 sec)\n","INFO:tensorflow:global_step/sec: 124.866\n","INFO:tensorflow:loss = 12.634665, step = 5301 (0.800 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 136.882\n","INFO:tensorflow:loss = 16.323835, step = 5401 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 124.5\n","INFO:tensorflow:loss = 6.9232507, step = 5501 (0.806 sec)\n","INFO:tensorflow:global_step/sec: 134.229\n","INFO:tensorflow:loss = 7.9834127, step = 5601 (0.743 sec)\n","INFO:tensorflow:global_step/sec: 134.866\n","INFO:tensorflow:loss = 11.070493, step = 5701 (0.740 sec)\n","INFO:tensorflow:global_step/sec: 124.151\n","INFO:tensorflow:loss = 7.0646567, step = 5801 (0.806 sec)\n","INFO:tensorflow:global_step/sec: 137.071\n","INFO:tensorflow:loss = 6.431694, step = 5901 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 124.528\n","INFO:tensorflow:loss = 6.797315, step = 6001 (0.806 sec)\n","INFO:tensorflow:global_step/sec: 135.017\n","INFO:tensorflow:loss = 8.136586, step = 6101 (0.737 sec)\n","INFO:tensorflow:global_step/sec: 135.519\n","INFO:tensorflow:loss = 6.2746034, step = 6201 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 125.731\n","INFO:tensorflow:loss = 14.237473, step = 6301 (0.800 sec)\n","INFO:tensorflow:global_step/sec: 133.119\n","INFO:tensorflow:loss = 6.0140204, step = 6401 (0.749 sec)\n","INFO:tensorflow:global_step/sec: 127.422\n","INFO:tensorflow:loss = 7.968195, step = 6501 (0.785 sec)\n","INFO:tensorflow:global_step/sec: 136.35\n","INFO:tensorflow:loss = 9.31003, step = 6601 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 137.019\n","INFO:tensorflow:loss = 6.919338, step = 6701 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 125.682\n","INFO:tensorflow:loss = 3.7517161, step = 6801 (0.797 sec)\n","INFO:tensorflow:global_step/sec: 136.206\n","INFO:tensorflow:loss = 5.2113023, step = 6901 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 127.541\n","INFO:tensorflow:loss = 5.977385, step = 7001 (0.785 sec)\n","INFO:tensorflow:global_step/sec: 133.504\n","INFO:tensorflow:loss = 6.6589503, step = 7101 (0.746 sec)\n","INFO:tensorflow:global_step/sec: 137.495\n","INFO:tensorflow:loss = 15.162142, step = 7201 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 126.592\n","INFO:tensorflow:loss = 8.413854, step = 7301 (0.790 sec)\n","INFO:tensorflow:global_step/sec: 135.662\n","INFO:tensorflow:loss = 15.512436, step = 7401 (0.738 sec)\n","INFO:tensorflow:global_step/sec: 125.986\n","INFO:tensorflow:loss = 8.179763, step = 7501 (0.794 sec)\n","INFO:tensorflow:global_step/sec: 137.872\n","INFO:tensorflow:loss = 9.551397, step = 7601 (0.720 sec)\n","INFO:tensorflow:global_step/sec: 137.499\n","INFO:tensorflow:loss = 6.4525533, step = 7701 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 123.289\n","INFO:tensorflow:loss = 10.510655, step = 7801 (0.812 sec)\n","INFO:tensorflow:global_step/sec: 135.236\n","INFO:tensorflow:loss = 4.0127153, step = 7901 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 127.321\n","INFO:tensorflow:loss = 13.993199, step = 8001 (0.786 sec)\n","INFO:tensorflow:global_step/sec: 135.99\n","INFO:tensorflow:loss = 4.0660186, step = 8101 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 135.924\n","INFO:tensorflow:loss = 3.0661263, step = 8201 (0.736 sec)\n","INFO:tensorflow:global_step/sec: 126.969\n","INFO:tensorflow:loss = 9.035247, step = 8301 (0.789 sec)\n","INFO:tensorflow:global_step/sec: 136.544\n","INFO:tensorflow:loss = 5.6078105, step = 8401 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 124.337\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 11.992082, step = 8501 (0.808 sec)\n","INFO:tensorflow:global_step/sec: 135.913\n","INFO:tensorflow:loss = 8.3349, step = 8601 (0.737 sec)\n","INFO:tensorflow:global_step/sec: 136.869\n","INFO:tensorflow:loss = 8.206715, step = 8701 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 127.457\n","INFO:tensorflow:loss = 4.276661, step = 8801 (0.784 sec)\n","INFO:tensorflow:global_step/sec: 135.664\n","INFO:tensorflow:loss = 11.074739, step = 8901 (0.738 sec)\n","INFO:tensorflow:global_step/sec: 126.115\n","INFO:tensorflow:loss = 11.588633, step = 9001 (0.791 sec)\n","INFO:tensorflow:global_step/sec: 137.675\n","INFO:tensorflow:loss = 0.9723448, step = 9101 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 134.551\n","INFO:tensorflow:loss = 5.3092785, step = 9201 (0.743 sec)\n","INFO:tensorflow:global_step/sec: 124.945\n","INFO:tensorflow:loss = 4.391673, step = 9301 (0.796 sec)\n","INFO:tensorflow:global_step/sec: 137.624\n","INFO:tensorflow:loss = 5.2582364, step = 9401 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 127.502\n","INFO:tensorflow:loss = 2.9472566, step = 9501 (0.786 sec)\n","INFO:tensorflow:global_step/sec: 135.355\n","INFO:tensorflow:loss = 4.682909, step = 9601 (0.736 sec)\n","INFO:tensorflow:global_step/sec: 134.423\n","INFO:tensorflow:loss = 4.3727727, step = 9701 (0.744 sec)\n","INFO:tensorflow:global_step/sec: 126.599\n","INFO:tensorflow:loss = 1.0671649, step = 9801 (0.793 sec)\n","INFO:tensorflow:global_step/sec: 133.356\n","INFO:tensorflow:loss = 1.1419139, step = 9901 (0.752 sec)\n","INFO:tensorflow:global_step/sec: 125.762\n","INFO:tensorflow:loss = 9.346687, step = 10001 (0.796 sec)\n","INFO:tensorflow:global_step/sec: 135.028\n","INFO:tensorflow:loss = 17.463984, step = 10101 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 135.5\n","INFO:tensorflow:loss = 2.7579918, step = 10201 (0.737 sec)\n","INFO:tensorflow:global_step/sec: 126.837\n","INFO:tensorflow:loss = 5.684419, step = 10301 (0.791 sec)\n","INFO:tensorflow:global_step/sec: 135.593\n","INFO:tensorflow:loss = 5.272672, step = 10401 (0.738 sec)\n","INFO:tensorflow:global_step/sec: 125.768\n","INFO:tensorflow:loss = 3.4233675, step = 10501 (0.795 sec)\n","INFO:tensorflow:global_step/sec: 131.872\n","INFO:tensorflow:loss = 5.9950337, step = 10601 (0.758 sec)\n","INFO:tensorflow:global_step/sec: 135.691\n","INFO:tensorflow:loss = 0.78357685, step = 10701 (0.740 sec)\n","INFO:tensorflow:global_step/sec: 125.624\n","INFO:tensorflow:loss = 6.1845922, step = 10801 (0.792 sec)\n","INFO:tensorflow:global_step/sec: 137.076\n","INFO:tensorflow:loss = 2.066514, step = 10901 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 126.746\n","INFO:tensorflow:loss = 5.885772, step = 11001 (0.793 sec)\n","INFO:tensorflow:global_step/sec: 134.55\n","INFO:tensorflow:loss = 7.4798923, step = 11101 (0.742 sec)\n","INFO:tensorflow:global_step/sec: 135.465\n","INFO:tensorflow:loss = 7.198793, step = 11201 (0.740 sec)\n","INFO:tensorflow:global_step/sec: 125.93\n","INFO:tensorflow:loss = 6.4660797, step = 11301 (0.794 sec)\n","INFO:tensorflow:global_step/sec: 137.236\n","INFO:tensorflow:loss = 3.142075, step = 11401 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 127.428\n","INFO:tensorflow:loss = 5.8608212, step = 11501 (0.785 sec)\n","INFO:tensorflow:global_step/sec: 134.952\n","INFO:tensorflow:loss = 4.233252, step = 11601 (0.740 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 136.73\n","INFO:tensorflow:loss = 3.6423123, step = 11701 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 127.396\n","INFO:tensorflow:loss = 2.3514652, step = 11801 (0.783 sec)\n","INFO:tensorflow:global_step/sec: 133.625\n","INFO:tensorflow:loss = 4.343174, step = 11901 (0.750 sec)\n","INFO:tensorflow:global_step/sec: 125.111\n","INFO:tensorflow:loss = 2.2058659, step = 12001 (0.797 sec)\n","INFO:tensorflow:global_step/sec: 135.9\n","INFO:tensorflow:loss = 3.4984634, step = 12101 (0.738 sec)\n","INFO:tensorflow:global_step/sec: 135.198\n","INFO:tensorflow:loss = 2.4561772, step = 12201 (0.738 sec)\n","INFO:tensorflow:global_step/sec: 125.754\n","INFO:tensorflow:loss = 3.783059, step = 12301 (0.797 sec)\n","INFO:tensorflow:global_step/sec: 135.454\n","INFO:tensorflow:loss = 6.8978195, step = 12401 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 127.712\n","INFO:tensorflow:loss = 2.7153256, step = 12501 (0.785 sec)\n","INFO:tensorflow:global_step/sec: 134.13\n","INFO:tensorflow:loss = 0.87610674, step = 12601 (0.749 sec)\n","INFO:tensorflow:global_step/sec: 134.169\n","INFO:tensorflow:loss = 4.7581844, step = 12701 (0.740 sec)\n","INFO:tensorflow:global_step/sec: 123.845\n","INFO:tensorflow:loss = 2.7127976, step = 12801 (0.812 sec)\n","INFO:tensorflow:global_step/sec: 135.537\n","INFO:tensorflow:loss = 3.1332703, step = 12901 (0.737 sec)\n","INFO:tensorflow:global_step/sec: 127.256\n","INFO:tensorflow:loss = 10.296355, step = 13001 (0.784 sec)\n","INFO:tensorflow:global_step/sec: 136.103\n","INFO:tensorflow:loss = 6.7087207, step = 13101 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 136.516\n","INFO:tensorflow:loss = 5.7758913, step = 13201 (0.736 sec)\n","INFO:tensorflow:global_step/sec: 122.999\n","INFO:tensorflow:loss = 3.4433618, step = 13301 (0.813 sec)\n","INFO:tensorflow:global_step/sec: 136.119\n","INFO:tensorflow:loss = 2.949686, step = 13401 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 128.557\n","INFO:tensorflow:loss = 5.261222, step = 13501 (0.774 sec)\n","INFO:tensorflow:global_step/sec: 138.229\n","INFO:tensorflow:loss = 1.3575631, step = 13601 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 134.656\n","INFO:tensorflow:loss = 0.8220044, step = 13701 (0.743 sec)\n","INFO:tensorflow:global_step/sec: 127.244\n","INFO:tensorflow:loss = 2.2081447, step = 13801 (0.787 sec)\n","INFO:tensorflow:global_step/sec: 135.491\n","INFO:tensorflow:loss = 6.330014, step = 13901 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 126.15\n","INFO:tensorflow:loss = 2.2978156, step = 14001 (0.798 sec)\n","INFO:tensorflow:global_step/sec: 134.717\n","INFO:tensorflow:loss = 0.407389, step = 14101 (0.737 sec)\n","INFO:tensorflow:global_step/sec: 136.611\n","INFO:tensorflow:loss = 3.316762, step = 14201 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 125.558\n","INFO:tensorflow:loss = 3.7517693, step = 14301 (0.800 sec)\n","INFO:tensorflow:global_step/sec: 134.252\n","INFO:tensorflow:loss = 5.4751277, step = 14401 (0.744 sec)\n","INFO:tensorflow:global_step/sec: 127.95\n","INFO:tensorflow:loss = 5.030821, step = 14501 (0.784 sec)\n","INFO:tensorflow:global_step/sec: 135.48\n","INFO:tensorflow:loss = 2.1124043, step = 14601 (0.736 sec)\n","INFO:tensorflow:global_step/sec: 134.071\n","INFO:tensorflow:loss = 2.2076526, step = 14701 (0.749 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 126.877\n","INFO:tensorflow:loss = 0.6925531, step = 14801 (0.787 sec)\n","INFO:tensorflow:global_step/sec: 135.772\n","INFO:tensorflow:loss = 0.6080221, step = 14901 (0.737 sec)\n","INFO:tensorflow:global_step/sec: 127.521\n","INFO:tensorflow:loss = 1.2456927, step = 15001 (0.785 sec)\n","INFO:tensorflow:global_step/sec: 136.846\n","INFO:tensorflow:loss = 0.39504007, step = 15101 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 136.111\n","INFO:tensorflow:loss = 2.9151976, step = 15201 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 123.753\n","INFO:tensorflow:loss = 2.1115937, step = 15301 (0.804 sec)\n","INFO:tensorflow:global_step/sec: 135.961\n","INFO:tensorflow:loss = 1.3160815, step = 15401 (0.740 sec)\n","INFO:tensorflow:global_step/sec: 125.893\n","INFO:tensorflow:loss = 1.967402, step = 15501 (0.792 sec)\n","INFO:tensorflow:global_step/sec: 137.401\n","INFO:tensorflow:loss = 10.011297, step = 15601 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 136.463\n","INFO:tensorflow:loss = 6.830148, step = 15701 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 126.207\n","INFO:tensorflow:loss = 0.08932415, step = 15801 (0.792 sec)\n","INFO:tensorflow:global_step/sec: 137.653\n","INFO:tensorflow:loss = 2.2601237, step = 15901 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 128.131\n","INFO:tensorflow:loss = 0.762013, step = 16001 (0.782 sec)\n","INFO:tensorflow:global_step/sec: 133.58\n","INFO:tensorflow:loss = 2.6307652, step = 16101 (0.751 sec)\n","INFO:tensorflow:global_step/sec: 137.388\n","INFO:tensorflow:loss = 2.485742, step = 16201 (0.725 sec)\n","INFO:tensorflow:global_step/sec: 126.108\n","INFO:tensorflow:loss = 8.157104, step = 16301 (0.794 sec)\n","INFO:tensorflow:global_step/sec: 137.104\n","INFO:tensorflow:loss = 1.952759, step = 16401 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 127.114\n","INFO:tensorflow:loss = 1.573993, step = 16501 (0.787 sec)\n","INFO:tensorflow:global_step/sec: 135.77\n","INFO:tensorflow:loss = 3.664827, step = 16601 (0.738 sec)\n","INFO:tensorflow:global_step/sec: 137.151\n","INFO:tensorflow:loss = 0.1859701, step = 16701 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 124.789\n","INFO:tensorflow:loss = 3.288063, step = 16801 (0.800 sec)\n","INFO:tensorflow:global_step/sec: 136.319\n","INFO:tensorflow:loss = 5.1004643, step = 16901 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 127.875\n","INFO:tensorflow:loss = 2.8657103, step = 17001 (0.781 sec)\n","INFO:tensorflow:global_step/sec: 139.033\n","INFO:tensorflow:loss = 1.7862599, step = 17101 (0.720 sec)\n","INFO:tensorflow:global_step/sec: 135.038\n","INFO:tensorflow:loss = 1.3919874, step = 17201 (0.740 sec)\n","INFO:tensorflow:global_step/sec: 126.281\n","INFO:tensorflow:loss = 1.3239704, step = 17301 (0.790 sec)\n","INFO:tensorflow:global_step/sec: 139.259\n","INFO:tensorflow:loss = 0.6507178, step = 17401 (0.720 sec)\n","INFO:tensorflow:global_step/sec: 125.771\n","INFO:tensorflow:loss = 1.9263774, step = 17501 (0.795 sec)\n","INFO:tensorflow:global_step/sec: 138.426\n","INFO:tensorflow:loss = 6.654863, step = 17601 (0.723 sec)\n","INFO:tensorflow:global_step/sec: 137.726\n","INFO:tensorflow:loss = 1.7631601, step = 17701 (0.727 sec)\n","INFO:tensorflow:global_step/sec: 128.398\n","INFO:tensorflow:loss = 0.72732455, step = 17801 (0.779 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 137.556\n","INFO:tensorflow:loss = 0.4283558, step = 17901 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 125.006\n","INFO:tensorflow:loss = 0.8747641, step = 18001 (0.797 sec)\n","INFO:tensorflow:global_step/sec: 137.344\n","INFO:tensorflow:loss = 0.39599264, step = 18101 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 135.639\n","INFO:tensorflow:loss = 1.3521464, step = 18201 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 125.639\n","INFO:tensorflow:loss = 4.2518077, step = 18301 (0.796 sec)\n","INFO:tensorflow:global_step/sec: 137.027\n","INFO:tensorflow:loss = 0.3902916, step = 18401 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 127.288\n","INFO:tensorflow:loss = 1.9845206, step = 18501 (0.783 sec)\n","INFO:tensorflow:global_step/sec: 136.972\n","INFO:tensorflow:loss = 1.4177113, step = 18601 (0.730 sec)\n","INFO:tensorflow:global_step/sec: 137.563\n","INFO:tensorflow:loss = 0.26515934, step = 18701 (0.723 sec)\n","INFO:tensorflow:global_step/sec: 127.805\n","INFO:tensorflow:loss = 1.8354334, step = 18801 (0.787 sec)\n","INFO:tensorflow:global_step/sec: 136.512\n","INFO:tensorflow:loss = 1.1424966, step = 18901 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 126.778\n","INFO:tensorflow:loss = 3.143929, step = 19001 (0.789 sec)\n","INFO:tensorflow:global_step/sec: 135.304\n","INFO:tensorflow:loss = 2.5688775, step = 19101 (0.736 sec)\n","INFO:tensorflow:global_step/sec: 138.24\n","INFO:tensorflow:loss = 1.2896683, step = 19201 (0.723 sec)\n","INFO:tensorflow:global_step/sec: 127.612\n","INFO:tensorflow:loss = 2.504179, step = 19301 (0.786 sec)\n","INFO:tensorflow:global_step/sec: 136.934\n","INFO:tensorflow:loss = 3.0693932, step = 19401 (0.730 sec)\n","INFO:tensorflow:global_step/sec: 127.912\n","INFO:tensorflow:loss = 0.17308721, step = 19501 (0.781 sec)\n","INFO:tensorflow:global_step/sec: 134.208\n","INFO:tensorflow:loss = 0.23646091, step = 19601 (0.746 sec)\n","INFO:tensorflow:global_step/sec: 134.768\n","INFO:tensorflow:loss = 2.2058258, step = 19701 (0.740 sec)\n","INFO:tensorflow:global_step/sec: 127.852\n","INFO:tensorflow:loss = 0.49054012, step = 19801 (0.782 sec)\n","INFO:tensorflow:global_step/sec: 136.988\n","INFO:tensorflow:loss = 1.9152452, step = 19901 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 128.072\n","INFO:tensorflow:loss = 1.3244157, step = 20001 (0.780 sec)\n","INFO:tensorflow:global_step/sec: 137.065\n","INFO:tensorflow:loss = 0.98051816, step = 20101 (0.728 sec)\n","INFO:tensorflow:global_step/sec: 136.844\n","INFO:tensorflow:loss = 2.890137, step = 20201 (0.736 sec)\n","INFO:tensorflow:global_step/sec: 124.684\n","INFO:tensorflow:loss = 1.7878436, step = 20301 (0.800 sec)\n","INFO:tensorflow:global_step/sec: 138.077\n","INFO:tensorflow:loss = 1.7284685, step = 20401 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 127.163\n","INFO:tensorflow:loss = 1.0578707, step = 20501 (0.787 sec)\n","INFO:tensorflow:global_step/sec: 136.591\n","INFO:tensorflow:loss = 1.8466187, step = 20601 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 136.379\n","INFO:tensorflow:loss = 0.60785794, step = 20701 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 127.278\n","INFO:tensorflow:loss = 1.1589156, step = 20801 (0.788 sec)\n","INFO:tensorflow:global_step/sec: 135.503\n","INFO:tensorflow:loss = 1.5211792, step = 20901 (0.742 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 123.279\n","INFO:tensorflow:loss = 1.1768968, step = 21001 (0.805 sec)\n","INFO:tensorflow:global_step/sec: 135.699\n","INFO:tensorflow:loss = 0.4111416, step = 21101 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 137.784\n","INFO:tensorflow:loss = 1.3886865, step = 21201 (0.726 sec)\n","INFO:tensorflow:global_step/sec: 128.29\n","INFO:tensorflow:loss = 3.1211743, step = 21301 (0.776 sec)\n","INFO:tensorflow:global_step/sec: 135.878\n","INFO:tensorflow:loss = 1.3276843, step = 21401 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 126.715\n","INFO:tensorflow:loss = 0.22026868, step = 21501 (0.789 sec)\n","INFO:tensorflow:global_step/sec: 137.269\n","INFO:tensorflow:loss = 0.8374204, step = 21601 (0.728 sec)\n","INFO:tensorflow:global_step/sec: 135.05\n","INFO:tensorflow:loss = 1.6549548, step = 21701 (0.740 sec)\n","INFO:tensorflow:global_step/sec: 127.661\n","INFO:tensorflow:loss = 0.29935893, step = 21801 (0.781 sec)\n","INFO:tensorflow:global_step/sec: 135.496\n","INFO:tensorflow:loss = 0.33687344, step = 21901 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 123.957\n","INFO:tensorflow:loss = 0.39265233, step = 22001 (0.808 sec)\n","INFO:tensorflow:global_step/sec: 137.031\n","INFO:tensorflow:loss = 0.78304714, step = 22101 (0.732 sec)\n","INFO:tensorflow:global_step/sec: 138.221\n","INFO:tensorflow:loss = 0.39012775, step = 22201 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 124.999\n","INFO:tensorflow:loss = 8.309049, step = 22301 (0.799 sec)\n","INFO:tensorflow:global_step/sec: 135.384\n","INFO:tensorflow:loss = 0.91771424, step = 22401 (0.739 sec)\n","INFO:tensorflow:global_step/sec: 125.953\n","INFO:tensorflow:loss = 2.963328, step = 22501 (0.796 sec)\n","INFO:tensorflow:global_step/sec: 136.777\n","INFO:tensorflow:loss = 1.2225488, step = 22601 (0.729 sec)\n","INFO:tensorflow:global_step/sec: 136.414\n","INFO:tensorflow:loss = 0.66046584, step = 22701 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 127.251\n","INFO:tensorflow:loss = 0.12307622, step = 22801 (0.786 sec)\n","INFO:tensorflow:global_step/sec: 136.073\n","INFO:tensorflow:loss = 0.071482785, step = 22901 (0.734 sec)\n","INFO:tensorflow:global_step/sec: 124.959\n","INFO:tensorflow:loss = 0.32248712, step = 23001 (0.800 sec)\n","INFO:tensorflow:global_step/sec: 134.413\n","INFO:tensorflow:loss = 0.19337901, step = 23101 (0.745 sec)\n","INFO:tensorflow:global_step/sec: 136.385\n","INFO:tensorflow:loss = 1.7447524, step = 23201 (0.735 sec)\n","INFO:tensorflow:global_step/sec: 125.055\n","INFO:tensorflow:loss = 0.70953274, step = 23301 (0.800 sec)\n","INFO:tensorflow:global_step/sec: 136.275\n","INFO:tensorflow:loss = 0.05769173, step = 23401 (0.731 sec)\n","INFO:tensorflow:global_step/sec: 126.955\n","INFO:tensorflow:loss = 0.12649207, step = 23501 (0.788 sec)\n","INFO:tensorflow:global_step/sec: 138.717\n","INFO:tensorflow:loss = 0.43271437, step = 23601 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 133.464\n","INFO:tensorflow:loss = 1.6421493, step = 23701 (0.747 sec)\n","INFO:tensorflow:global_step/sec: 126.661\n","INFO:tensorflow:loss = 1.7562207, step = 23801 (0.792 sec)\n","INFO:tensorflow:global_step/sec: 137.625\n","INFO:tensorflow:loss = 2.0394802, step = 23901 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 127.757\n","INFO:tensorflow:loss = 3.5645278, step = 24001 (0.786 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 136.503\n","INFO:tensorflow:loss = 0.29781562, step = 24101 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 136.639\n","INFO:tensorflow:loss = 3.680334, step = 24201 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 128.384\n","INFO:tensorflow:loss = 0.81191015, step = 24301 (0.778 sec)\n","INFO:tensorflow:global_step/sec: 136.141\n","INFO:tensorflow:loss = 1.0568783, step = 24401 (0.733 sec)\n","INFO:tensorflow:global_step/sec: 126.553\n","INFO:tensorflow:loss = 0.30457726, step = 24501 (0.792 sec)\n","INFO:tensorflow:global_step/sec: 138.148\n","INFO:tensorflow:loss = 0.19197173, step = 24601 (0.724 sec)\n","INFO:tensorflow:global_step/sec: 138.53\n","INFO:tensorflow:loss = 0.20814349, step = 24701 (0.722 sec)\n","INFO:tensorflow:global_step/sec: 127.845\n","INFO:tensorflow:loss = 1.7888054, step = 24801 (0.778 sec)\n","INFO:tensorflow:global_step/sec: 135.584\n","INFO:tensorflow:loss = 3.1667922, step = 24901 (0.743 sec)\n","INFO:tensorflow:Saving checkpoints for 25000 into /tmp/tmppw5q4h5g/cnn_pretrained/model.ckpt.\n","INFO:tensorflow:Loss for final step: 0.11525925.\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2018-03-06-17:07:05\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmppw5q4h5g/cnn_pretrained/model.ckpt-25000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Finished evaluation at 2018-03-06-17:07:07\n","INFO:tensorflow:Saving dict for global step 25000: accuracy = 0.86028, accuracy_baseline = 0.5, auc = 0.9103301, auc_precision_recall = 0.92412734, average_loss = 0.83090985, global_step = 25000, label/mean = 0.5, loss = 83.09099, prediction/mean = 0.46199763\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmppw5q4h5g/cnn_pretrained/model.ckpt-25000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"}]},{"metadata":{"id":"U5l6_C5uTVk4","colab_type":"text"},"cell_type":"markdown","source":["## Results"]},{"metadata":{"id":"XKVCyX68vq-c","colab_type":"text"},"cell_type":"markdown","source":["### Launching TensorBoard\n","\n","Now we can launch TensorBoard and see how the different models we've trained compare against each other in terms of training time and performance.\n","\n","In a terminal, do\n","```bash\n","> tensorboard --logdir={model_dir}\n","```\n","\n","We can visualize many metrics collected while training and testing, including the loss function values of each model at each training step, and the precision-recall curves. This is of course most useful to select which model works best for our use-case as well as how to choose classification thresholds.\n","\n","![PR curve](https://raw.githubusercontent.com/eisenjulian/nlp_estimator_tutorial/master/pr_curves.png) \n","\n","![loss](https://raw.githubusercontent.com/eisenjulian/nlp_estimator_tutorial/master/loss.png)\n"]},{"metadata":{"id":"_2dw3iYOSuNg","colab_type":"text"},"cell_type":"markdown","source":["### Getting Predictions\n","\n","To get predictions on new sentences we can use the `predict` method in the `Estimator` instances, which will load the latest checkpoint for each model and evaluate on the unseen examples. But before passing the data into the model we have to clean up, tokenize and map each token to the corresponding index, as shown here.\n","\n","It's worth noting that the checkpoint itelf is not enough to make predictions since the actual code used to build the estimator is necessary as well, in order to map the saved weights into the corresponding tensors, so it's a good practice associate saved checkpoints with the branch of code with which they were created.\n","\n","If your are interested in exporting the models to disk in a fully recoverable way you might want to look into the [SavedModel](https://www.tensorflow.org/programmers_guide/saved_model#using_savedmodel_with_estimators) class, specially useful for serving your model through an API using [TensorFlow Serving](https://github.com/tensorflow/serving)."]},{"metadata":{"id":"34K8O0bTNj-b","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":185},"outputId":"eef27d40-63ce-4863-8720-7669a39ba03a","executionInfo":{"status":"ok","timestamp":1523274345221,"user_tz":180,"elapsed":937,"user":{"displayName":"Julian Eisenschlos","photoUrl":"//lh3.googleusercontent.com/-64ZxueD_a5k/AAAAAAAAAAI/AAAAAAAAY_I/SjD0k9jJ8Ug/s50-c-k-no/photo.jpg","userId":"112692138304087361987"}}},"cell_type":"code","source":["def text_to_index(sentence):\n","    # Remove punctuation characters except for the apostrophe\n","    translator = str.maketrans('', '', string.punctuation.replace(\"'\", ''))\n","    tokens = sentence.translate(translator).lower().split()\n","    return np.array([1] + [word_index[t] if t in word_index else oov_id for t in tokens])\n","\n","def print_predictions(sentences):\n","    indexes = [text_to_index(sentence) for sentence in sentences]\n","    x = sequence.pad_sequences(indexes, \n","                               maxlen=sentence_size, \n","                               truncating='post',\n","                               padding='post',\n","                               value=pad_id)\n","    length = np.array([min(len(x), sentence_size) for x in indexes])\n","    predict_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": x, \"len\": length}, shuffle=False)\n","    predictions = {}\n","    for path, classifier in all_classifiers.items():\n","        predictions[path] = [p['logistic'][0] for p in classifier.predict(input_fn=predict_input_fn)]\n","    for idx, sentence in enumerate(sentences):\n","        print(sentence)\n","        for path in all_classifiers:\n","            print(\"\\t{} {}\".format(path, predictions[path][idx]))\n","            \n","print_predictions([\n","    'I really liked the movie!',\n","    'Hated every second of it...'])"],"execution_count":16,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpj4vob2jo/bow_sparse/model.ckpt-25000\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I really liked the movie!\n","\t/tmp/tmpj4vob2jo/bow_sparse 0.5684791803359985\n","Hated every second of it...\n","\t/tmp/tmpj4vob2jo/bow_sparse 0.5243321061134338\n"],"name":"stdout"}]},{"metadata":{"id":"PuycPjrrvq-d","colab_type":"text"},"cell_type":"markdown","source":["### Other resources\n","\n","In this notebook, we explored how to use estimators for text classification, in particular for the IMDB Reviews Dataset. We trained and visualized our own embeddings, as well as loaded pre-trained ones. We started from a simple baseline and made our way to convolutional neural networks and LSTMs.\n","\n","For more details, be sure to check out:\n","\n"," * The complete [source code](https://github.com) for this blog post.\n"," * A [Jupyter notebook](https://github.com) that can run locally, or on Colaboratory.\n"," * The TensorFlow [Embedding](https://www.tensorflow.org/programmers_guide/embedding) guide.\n"," * The TensorFlow [Vector Representation of Words](https://www.tensorflow.org/tutorials/word2vec) tutorial.\n"," * The *NLTK* [Processing Raw Text](http://www.nltk.org/book/ch03.html) chapter on how to design langage pipelines.\n"," \n","In a following tutorial, we will show how to build a model using eager execution, work with out-of-memory datasets, train in Cloud ML, and deploy with TensorFlow Serving.\n","\n","\n","----------\n","\n","*Thanks for reading! If you like you can find us online at [ruder.io](http://ruder.io/) and [@eisenjulian](https://twitter.com/eisenjulian). Send our way all your feedback and questions.*"]}]}